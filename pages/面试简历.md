更新时间：2025/5/24
# 简历

# TODO：

- [ ] 多个分布式定时任务框架的对比
- [X] 进程间通信
- [X] XXL 的八股
- [X] RabbitMq 的八股
- [ ] 把 Spring AI 的代码写出来
- [X] 复习 OSS 的

BR：什么情况用，可能有哪些问题，该如何解决

为什么。怎么做的，优点缺点

- [ ] 设计模式
- [X] 防止点赞覆盖的各种数据量下的方案
- [X] （3.1.1）第三方 AI 接口、流量限流
- [X] 点赞，不用唯一索引改分布式锁
- [X] 分页解决的问题：
- [X] redis：
- [ ] 并发：
- [ ] 分布式：

# 八股部分

## 计网

1. 讲讲从输入网址开始，全流程是什么：

### 应用层

1. cookie 和 session 的区别是什么

   1. 存储位置
      1. cookie 存储在客户端，随着 http 请求放在响应头中发送到服务器
      2. session 存储在服务器端，客户端返回的 cookie 中包含后端给的 sessionID，从而来查询 session 中的信息
   2. 数据容量
      1. cookie 受浏览器限制，单个也不大，毕竟要塞 http 里
      2. session 在服务器上，看服务器
   3. 生命周期
      1. cookie 可以设置过期时间，过期后删除，或者设置为会话 cookie，浏览器关闭，自动删除
      2. session 在默认情况下，线程关闭就关闭，也可以设置过期时间
2. token：

   - 是什么：Token 是一种服务器生成并发送给客户端的字符串，代表用户的身份或权限。客户端在后续请求中需要携带这个 Token 来表明自己的身份。最常见的 Token 类型是 JWT (JSON Web Token)。
   - 如何工作 (以 JWT 为例) ：
     1. 用户使用用户名和密码请求登录。
     2. 服务器验证用户信息，如果成功，会生成一个 Token (JWT 包含头部、载荷和签名三部分，载荷可以包含用户 ID、过期时间等信息，签名用于验证 Token 的真实性)。
     3. 服务器将 Token 返回给客户端。
     4. 客户端将 Token 存储起来 (通常在 `localStorage`、`sessionStorage` 或 Cookie 中)。
     5. 客户端在后续需要认证的请求中，通常将 Token 放在 HTTP 请求头 `Authorization` 中 (例如 `Authorization: Bearer <token>`)。
     6. 服务器接收到请求后，验证 Token 的签名和有效性 (如是否过期)。如果验证通过，则处理请求。

   1. 特点：
      1. 无状态 (Stateless) ：服务器端通常不需要存储 Token (JWT 的设计思想)。服务器只需根据密钥验证 Token 的签名即可，减轻了服务器存储压力。这使得应用更容易扩展，特别适合分布式系统和微服务架构。
      2. 客户端存储：Token 由客户端负责存储和在请求时发送。
      3. 包含信息：JWT Token 本身可以包含一些非敏感的用户信息 (Payload 部分)，服务器解码后可以直接使用，减少了查询数据库的次数。
      4. 安全性：
         1. 通过签名机制防止数据被篡改。
         2. Token 的传输需要使用 HTTPS 来防止中间人窃听。
         3. 如果 Token 存储在 `localStorage`，可以避免 CSRF 攻击 (因为 `localStorage` 不会自动随请求发送)，但可能受到 XSS 攻击 (恶意脚本可以读取 `localStorage`)。
      5. 一次性：Token 一旦签发，在有效期内通常难以主动使其失效 (除非服务器维护一个黑名单，但这又引入了状态)。通常依赖过期时间。
3. 禁用了 cookie，session 还能用吗

   1. cookie 这条路走不通了，但是还可以放到 url 里面
4. Https 为什么安全

   1. https 是 http+ssl/TLS
   2. SSL 的实现过程：
      1. 传输过程中不被篡改：服务器提供一个生产的 hash，客户端获得内容后根据内容重新计算这个 hash，通过比较两个 hash 是否相等来判断内容是否被修改
      2. 建立加密链接：
         1. 服务器向客户端发送数字证书，证书中包含公钥。
         2. 客户端生产一个随机数并用公钥加密，发送回服务器，服务器用私钥解密
         3. 服务器通过这个随机数和之前约定好的算法，生成对衬的会话密钥
         4. 双方通过这个密钥进行沟通
5. TCP/UDP

### 传输层

1. 三次握手

   1. TCP 为什么需要三次握手
      1. 防止历史消息创建连接，浪费服务器资源
      2. 三次握手才能保证双方序列号都加 1
   2. 第三次握手时丢失了怎么办
      1. ACK 不会重传，服务器的 SYN-ACK 会超时重传
   3. 第二次握手丢失了怎么办
      1. 双方都会重传
      2. 对服务器来说，第三次握手丢失，和第二次握手丢失是相同的，都是没收到回复，都会重传
      3. 对客户端来说，等于第一次发出 syn，没有收到回复，所以也会重传
2. 四次挥手

   1. 客户端主动调用关闭，发送一个 FIN 给客户端，然后进入 FIN_WAIT_1 状态
   2. 服务器收到 FIN 之后，马上回复一个 ACK，之后进入 CLOSE_WAIT 状态，然后向缓冲区中插入文件结束符 EOF，当服务器用 read 函数读取到 EOF 后，相当于接受了所有的数据了，就发送完所有的数据后，发送 FIN 给客户端，并进入 LAST_ACK
   3. 客户端收到之后，发送 ACK 给服务器，进入 TIME_WAIT 状态，2MSL 时间之后，进入 CLOSE 状态
      1. 为了防止服务器发的数据还没接受完（网络延迟）
   4. 服务器收到 ACK 之后进入 CLOSE 状态
3. TCP 与 UDP 的区别

   1. UDP 不需要提前建立连接，同时支持一对多和多对多，此外 UDP 是最大努力尝试，且没有拥塞控制和流量控制机制。最后 UDP 是一个包一个包发送的，可能会丢包和乱序
4. TCP 的拥塞控制

   1. 维护一个拥塞窗口和发送窗口来实现
   2. 当网络中没有出现拥塞，拥塞窗口增大，出现了，则减小
      1. 拥塞是通过发送方规定时间内没有收到 ACK 报文来实现的
   3. 拥塞控制算法
      1. 慢启动
         1. 当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1
      2. 拥塞避免算法
         1. 每当收到一个 ACK 时，cwnd 增加 1/cwnd
      3. 拥塞发生算法
         1. 发生超时重传时
            1. ssthresh 设为 cwnd/2

            - cwnd 重置为 1 （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）
            - 然后开始慢启动
         2. 发送快速重传时
            1. cwnd 设为 cwnd/2
            2. ssthresh = cwnd
      4. 快速恢复

### 网络场景

1. 打开百度首页之后发生的：
   1. 添加头部，组成包
      1. 应用层添加 http 头部
         1. 解析 URL，获取域名等
      2. 传输层添加 tcp 头部，包括源端口号和目标端口号
      3. 网络层添加 ip 头部
         1. DNS 解析，获取 IP 地址
      4. 链路层添加以太网头部，包含双方的 mac 地址
         1. 网卡添加 MAC 地址，通过 ARP 协议找目标 Mac 地址
         2. 在同一局域网中：ARP 在以太网中，通过 IP 协议广播，获得的 MAC 地址
         3. 在不同的局域网中：
            1. 构建 MAC 头部：
               - 主机 A 知道它不能直接将数据发送给 IP_C，而是需要通过默认网关 (Default Gateway) （通常是一个路由器）来转发。
               - 因此，主机 A 会执行上述 ARP 过程，但这次的目标 IP 地址是其默认网关的 IP 地址 (IP_Gateway) 。
               - 它会发送一个 ARP 请求，询问“谁拥有 IP_Gateway，请告诉我你的 MAC 地址”。
               - 默认网关会响应一个 ARP 应答，告诉主机 A 它的 MAC 地址 (MAC_Gateway)。

            - 发送过程中不断查询和修改目标 mac
              - 网关收到这个帧，解开它，看到 IP 头部的目标 IP 地址是 IP_C。
              - 网关会查询自己的路由表，找到下一跳的地址来将数据包转发给 IP_C。
              - 如果下一跳是另一个路由器，网关会重复类似的过程（可能需要 ARP 找到下一跳路由器的 MAC 地址）。
              - 如果 IP_C 所在的网络直接连接到这个网关，网关会检查其 ARP 缓存是否有 IP_C 的 MAC 地址。如果没有，它会在连接到 IP_C 的那个网络接口上发送 ARP 请求，以获取 IP_C 的 MAC 地址。然后用 IP_C 的 MAC 地址作为目标 MAC，自己的出接口 MAC 作为源 MAC，将数据包转发出去。
   2. 经过网卡，路由器，到对方网卡
   3. 去掉头部，暴露信息
      1. 目标网卡校验 MAC 地址，去除 MAC 头部后，发送给服务器
      2. 服务器查看 TCP 头部，获取端口号，然后放入缓存，返回 ACK
      3. HTTP 进程监听端口，获得 HTTP 头部，拆开，响应

## 操作系统

### 用户态和内核态

1. 什么是内核：

   1. 简单来说，内核（Kernel）是操作系统的核心部分，它负责管理系统的资源，并提供系统服务给应用程序使用。你可以把内核想象成一个管家，它管理着你的电脑的所有重要东西，比如：
      - CPU (中央处理器): 内核决定哪个程序能使用 CPU，以及使用多久。
      - 内存 (RAM): 内核负责分配内存给不同的程序，并防止它们互相干扰。
      - 设备 (硬盘, 显卡, 网卡等): 内核提供驱动程序来让电脑与各种硬件设备进行通信。
      - 文件系统: 内核允许你读取、写入和组织文件。
   2. 内核的主要功能包括：
      - 进程管理: 创建、销毁和管理进程（正在运行的程序）。
      - 内存管理: 分配、释放和管理内存空间。
      - 设备驱动: 提供接口来与硬件设备进行交互。
      - 系统调用: 提供一种方式让应用程序可以访问内核提供的服务。
      - 中断处理: 响应硬件事件并进行处理。
      - 文件系统支持: 管理文件和目录。
2. 什么是用户态和内核态

   1. 内核态：指的是 CPU 的一种特权级别，只有操作系统内核的代码才能运行在这种模式下。
3. 与进程的关系：

   1. 进程在运行的时候，可以在内核态和用户态之间切换。
      - 用户进程通常以用户态启动和运行。 大部分时间，程序都在执行用户态的代码，如计算、数据处理等。
      - 当用户进程需要操作系统提供的服务 (例如：读写文件，发送网络数据) 时，会发起一个 "系统调用" (System Call)。 系统调用会触发一个 "中断" (Interrupt)，CPU 会从用户态切换到内核态。
      - 操作系统内核的代码 (运行在内核态) 会处理这个系统调用， 为进程提供所需的服务。
      - 处理完成后，操作系统内核会将 CPU 切换回用户态，用户进程继续执行。

### 进程管理

1. 进程、线程、协程

   1. 协程：完全由用户调度，不需要内核参与
      1. 协程运行在线程之上。 它的实现并不涉及操作系统的内核调度。 一个线程可以同时运行多个协程。 换句话说，可以把线程看作是一个容器，协程在这个容器里“协作”运行。协程运行在线程中，因此它使用线程的资源。 包括：
         - 栈空间： 虽然协程比线程轻量级，但它仍然需要栈空间来存储局部变量、函数调用信息等。 协程的栈空间通常比线程的栈空间小得多。
         - 堆空间： 协程可以访问线程所拥有的堆空间，因此可以共享线程中的对象和数据。
         - CPU 时间片： 虽然协程的切换不涉及内核调度，但是线程仍然需要获得 CPU 时间片才能运行线程内的协程。
2. 进程的状态：

   1. 创建
   2. 就绪
   3. 运行
   4. 阻塞
   5. 结束
3. 进程上下文切换

   1. 进程上下文切换只能在内核态进行
   2. 首先理解 CPU 的上下文切换
      1. 包括寄存器和程序计数器，新的进来就要用新的
      2. 有三种：进程上下文切换、线程上下文切换和中断上下文切换。
   3. 进行切换类似，需要把上下文（虚拟内存，栈、全局变量、当前 CPU 上下文）等保存到 PCB 中，这个切换和加载新的上下文的过程就是进程上下文切换
4. 进程间通讯的方式

   1. Linuex 提供：
      - 管道
        - 匿名管道
          - 单向，只能在父子进程中
        - 命名管道
      - 消息队列
      - 共享内存
        - 共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中
      - 信号
        - 一种处理异步事件的方式。信号是比较复杂的通信方式，用于通知接收进程有某种事件发生，除了用于进程外，还可以发送信号给进程本身
      - 信号量
        - 和 Java 的信号量很像，操作系统中，服务于多进程
        - 比如在使用共享空间时，就可以通过信号量来控制拿取资源
      - socket
5. 进程调度算法有哪些

   1. FCFS
   2. _Shortest Job First, SJF_
   3. _Highest Response Ratio Next, HRRN_
      1. 先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行
         ![](static/STGEb2PuwoD2nMxiAz0cu8P5nI4.png)
   4. 时间片轮转（_Round Robin, RR）_
   5. 最高优先级（_Highest Priority First，HPF）_
      1. 分静态优先级和动态优先级
      2. 分抢占式和非抢占式
   6. 多级反馈队列（_Multilevel Feedback Queue_）

### 线程管理

1. 线程如何进行切换，切换之后的线程信息保存在哪里

   1. 保存上下文信息到 TCB 中（Thread control block，专门存储和管理线程信息的数据结构）
   2. 然后把控制权交给调度器，调度器根据算法决定要唤醒哪一个线程
2. 线程间的通信方法：加锁

   1. 互斥锁（mutex）
   2. 条件变量（cond）
      1. wait 的实现
   3. 读写锁
   4. 自旋锁
      1. 自旋锁通过 CPU 提供的 CAS 函数（_Compare And Swap_），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换
      2. 加锁过程：
         1. 第一步，查看锁的状态，如果锁是空闲的，进行第二步。
            1. 否则加锁失败的线程会「忙等待」，直到它拿到锁
               1. 可以用 while 不过最好是使用 CPU 提供的 `PAUSE` 指令来实现「忙等待」，因为可以减少循环等待时的耗电量
         2. 第二步，将锁设置为当前线程持有
      3. CAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的
   5. 信号量
      1.

### 锁

1. 锁是为线程服务的
2. 如何避免死锁：

   1. 加超时
   2. 顺序一致

### 内存管理

1. 虚拟内存和物理内存都划分为一个一个的页，内存中维护 页表 ，通过内存管理单元 （_MMU_） 来管理映射

   1. 在 Linux 下，每一页的大小为 4KB。Mysql 的页是 16KB，所以一个 Mysql 页由 4 个内存页组成，如果从内存写入 Mysql 时，某个页数据出错了，就会报错，然后根据 redolog 进行修复。所以是先写到 doublewrite buffer 中，再写入 mysql
2. 缺页异常：

   1. 进程访问的虚拟地址在页表中查不到时产生，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，继续进程执行
3. 虚拟地址：

   1. 分为页号与页内偏移量

### 中断

1. 针对 CPU 的

## Java 基础

### 数据类型

1. 有哪些基本数据类型，分别是多少位：

   1. 数值型
      1. 整数
         1. int - 4 字节，32 位
         2. short - 2 字节，16 位
         3. long - 8 字节，64 位
         4. byte - 1 字节，8 位
      2. 浮点数
         1. float - 4 字节，32 位
         2. double - 8 字节，64 位
   2. 布尔值
      1. 无明确字节大小
   3. 字符型 char
      1. 2 字节，16 位
2. 数据类型的转换方法有哪些：

   1. 隐式转换-从小到大
   2. 显示转换：从大到小，直接截断
   3. 目标类型.parse 目标类型()，从字符串转换到目标类型
   4. 数值之间转换
3. 为什么精确计算用 bigdecimal

   1. double 和 float 基于二进制浮点数进行计算，会无法精确表示 0.1 之类的数，而 bigdecimal 是 Math 下的包，通过一个 BigInteger 来表示值，一个 int 来表示标度
      1. BigInteger 也是 Math 下的包，通过数组来存储符号位和值
4. 自动装箱和自动拆箱

   1. 自动装箱是指在讲基本数据类型赋值给包装类，以及传基本数据类型给方法参数时，自动将其转换为包装类的机制
   2. 弊病：循环中可能导致多次装箱出很多无用的包装类
5. 为什么要有包装类

   1. Java 中大部分逻辑是面向类的，比如 ArrayList，sort 等集合和方法都需要对象才能使用，同时数值和字符串之间的转换也需要类来执行
   2. 成员变量和静态变量是和类一起存放在堆上，而方法变量则是直接放在栈帧里
6. 包装类的缓存：

   1. Integer 缓存了从-127 到 128 的内容
      1. 放在 Integer 类的内部，Integer 类内部维护了一个 IntegerCache 内部类，该类是一个静态内部类，其中包含一个 Integer 数组，用于存储缓存的 Integer 对象。
   2. 字符串常量池：
      1. 缓存内容：
         1. “” 创建的内容
         2. 字符串拼接的内容
         3. String.Inter() 的内容
      2. 位置：堆中
7. 字符串

   1. String、`StringBuilder` 与 `StringBuffer` 的区别
      1. 可变性：
         1. 1 不可变（内部数组被 final 修饰且私有），2、3 可变
      2. 线程安全性：
         1. 1、3 安全，builder 不安全
      3. 性能：
         1. 1 最底，线程不安全的性能最高
   2. 字符串拼接的方式
      1. + ：专门为 String 重载的运算符，内部是通过 Builder 来 apeend

         1. 多次调用的话，不会复用 Builder
      2. 直接使用 2、3 的 append 方法
   3. String 的 equal 是被重写过的，直接比较字符串的值是否相等

### 面向对象

1. 多态体现在哪些地方

   1. 多态指允许不同类的对象对同一个接口做出响应，即同一个接口，使用不同的实例而执行不同的操作
   2. 方法重载：
      1. 同一个类中有不同个不同参数的同名方法
   3. 方法重写：
      1. 子类重写父类的方法
   4. 接口和实现：
      1. 多个不同的类可以继承同一个接口，然后通过接口类型的引用来调用不同类的方法
   5. 向下转型和向上转型：
      1. 向上转型：子类通过父类的引用调用
      2. 向下转型：用父类调用的子类通过指定子类来转换回子类引用
2. 抽象类和普通类的区别：

   1. 抽象类不能被实例化，只能被继承，内部方法可以实现也可以不实现且允许成员变量，继承抽象类的类可以继承多个接口
3. 抽象类与接口的区别

   1. 抽象类主要可以提供大量的代码复用，而接口只是定义规范
   2. 接口可以被多重继承
4. 接口可以定义哪些方法？

   1. 抽象方法
      1. 所有类都必须实现抽象方法，也是抽象类中的默认方法，默认是 public abstract 的
   2. 默认方法
      1. Java8 引入，可以有具体的实现
   3. 静态方法
      1. Java8 引入，有具体的实现，直接通过类名调用
   4. 私有方法
      1. Java9 引入，为默认方法或者其他私有方法提供辅助，不能被实现类访问
5. 内部类

   1. 什么是内部类，为什么要内部类
      1. 内部类（尤其非静态内部类）可以方便地访问其外部类的所有成员（包括私有成员）
      2. 内部类仅为外部类服务，例如链表的 Node 类
   2. 有哪些内部类：
      - 成员内部类 (Member Inner Class) : 即非静态内部类。
      - 静态内部类 (Static Nested Class) : 有时也直接称为嵌套类。
      - 局部内部类 (Local Inner Class) : 定义在方法或代码块内部。
      - 匿名内部类 (Anonymous Inner Class) : 没有名字的内部类，通常用于快速实现接口或继承类。
   3. 非静态内部类和静态内部类的区别：
      1. 除了静态和非静态的常见区别之外，主要是非静态内部类有一个 outerClass 的引用指向外部类，可以直接读取外部类的全部属性和方法，包括 private 的，但是静态内部类不持有这个引用，因为是静态内部类
6. 如何实现深拷贝

   1. 实现 Cloneable 接口并重写 clone() 方法
      1. 要求对象和他的引用对象都实现 Cloneable 接口并重写 clone() 方法
   2. 序列化和反序列化
      1. 要求对象和他的引用对象都实现 serializable 接口
   3. 手动 new 新的对象并引用
7. Java 中创建对象有哪些方式

   1. new
   2. 反射的 newInstance
   3. clone 和序列化和反序列化
8. 如何获得私有对象：

   1. getter 方法
   2. 反射机制获得

### 反射

1. 在运行时，只要给定类名或者类，可以获得任意一个类的属性和方法并调用或者修改值
2. 反射是通过访问每个类的 Class 对象来执行的
3. 为什么反射慢：

   1. 反射会从方法数组中遍历查找，并且验证可见性

### 泛型

1. 泛型如何通过类型擦除来实现的：

   1. 在编辑阶段检查过类型正确之后，会把所有的泛型类型全部替换为 Object 根类
2. 泛型可以通过指定上（extends）下（super）界的方法来让类型擦除时替换为指定的类

   1. 上界：参数化的类型是 T 或者 T 的子类
   2. 下届：参数化的类型是 T 或者 T 的父类

### 注解

1. 什么是注解

   1. 注解是一种继承了 annotation 的特殊接口，可以在内部定义一些值，并在传参的时候使用。可以通过反射来检查类、方法、属性上是否存在某个注解，并且通过 getAnnotation 方法获取一个代理类，来输出注解中的各种信息。
2. 为什么要用注解：

   1. 各种框架中依赖注解来监测意图，比如 @Test
   2. 提供额外信息，比如 @Auth 来让过滤器处理他
3. 注解的类型：

   1. 源码级
   2. 类文件级
   3. 运行时注解
      1. 只有他能被反射解析
4. 作用域：

   1. 类级别
   2. 方法级别
   3. 字段级别

### 代理

1. 静态代理

   1. 开发者手写，在编译期就确定了
   2. 代理类与被代理类实现相同的接口，代理类中有被代理对象的引用，通过重写接口方法，在方法前后增加代理类的操作
2. 动态代理

   1. 在运行时动态产生的，通过反射机制或者第三方库实现
   2. JDK 动态代理
      1. 基于接口实现，被代理的类必须要实现接口
   3. CGlib 动态代理
      1. 生产被代理类的子类来实现

### 异常

1. 都继承了 Throwable 类

   1. Error：
      1. 程序无法处理的错误，如 JVM 崩溃等
   2. Exception：
      1. RuntimeException
         1. 数组越界之类的
      2. 非运行时异常：
         1. 程序员写代码时就应该防止出现的，如文件不存在等
2. 异常处理

   1. finally 中的 return 会覆盖 try 中的 return

### 序列化

1. 什么是序列化和反序列化

   1. 就是从类到字节数组和反过来的过程
   2. 需要实现 serializable 接口，通过 ObjectOutPutStream.writeObject(想序列化的类)来进行序列化
2. 序列化不保存静态变量

   1. 序列化的是对象，而不是类，多个类序列化时，会重复保存静态变量
   2. 静态变量会有 JVM 去元空间获取
3. FastJson 的实现和问题

   1. 是通过遍历 getter 方法来获取值的

### I/O

1. Java 常见的流：

   1. 字节流：
      1. InputStream
      2. OutputStream
   2. 字符流：
      1. Reader
      2. Writer
2. BIO、NIO、AIO

   1. BIO 同步 IO，线程发起 IO 之后，一直阻塞直到缓冲区就绪】
   2. NIO 同步非阻塞 IO，有一个 selector 线程来代替线程进行轮询，线程之间通过 notify 和 wait 进行交流。
      1. 所有的数据读写都必须通过 Buffer 进行。数据从 Channel 读入 Buffer，或者从 Buffer 写入 Channel
   3. AIO 异步非阻塞：
      - 异步 (Asynchronous) ：应用程序发起一个 I/O 操作后，不需要等待操作完成，可以立即返回并执行其他任务。当 I/O 操作实际完成后，操作系统会通知应用程序（通常通过回调函数或 `Future` 对象）。应用程序是被动接收结果的。
      - 非阻塞 (Non-blocking) ：发起 I/O 操作的线程不会被阻塞。

### SPI 与 API

SPI 是一种特殊的 API，它的核心思想是 “调用者定义接口，实现者提供实现，系统或框架动态发现并加载实现”

- 例如日志框架 (如 SLF4J, Logback, Log4j)： SLF4J 定义日志门面 API，具体的日志实现（Logback, Log4j2）作为服务提供者

## Java 集合类

![](static/TSY3b1oPloWZIKxWKRVcHsDEnAb.png)

### 线程安全类

1. 什么是 fail-fast 和 fail-safe
   1. 快速失败指的是迭代过程中修改集合，会改变 modcount 值，如果遍历到下一步时，modcount 值与预期值不符，那就说明有其他线程修改了这个集合，则抛出异常，终止遍历
   2. 安全失败指的是遍历时遍历集合到复制，不会触发异常，但是也无法感知到原集合上的修改
      1. 类似于可重复读，复制一个快照一直用
2. 基本的集合（util 包）里有哪些线程安全的
   1. HashTable 和 Vector，都是通过加 synchronize 的方法实现的
3. 并发集合（util.concurrent 包）
   1. Map
      1. ConcurrentHashMap
         1. 分段 CAS+ 锁的方式实现
         2. ConcurrentHaspMap 为什么实现的弱一致性
            1. 比如 get 等方法没有用锁，是从线程缓存中读取的
               假设有两个线程 A 和 B，最初 ConcurrentHashMap 中 `key` 的值为 0。
               1. 线程 A 执行 `put(key, 1)`。
               2. 线程 B 执行 `get(key)`。
                  线程 B _可能_ 在线程 A 的 `put` 操作完成之前执行 `get`，因此线程 B 可能读取到旧值 0。 但最终，由于 `volatile` 和底层内存模型的保证，线程 B 最终会看到 `key` 的值为 1。
      2. ConcurrentSkipListMap
   2. List
      1. CopyOnWriteArrayList
         1. 通过写时复制，也就是区分读和写，对读不做限制，都是读取的 volatile 的老数组，但是写的时候上 renentrylock，复制一个新的数组出来写入，写入完成之后，再修改引用完成数组的更新
   3. Queue
      1. ConcurrentLinkedQueue
         1. 通过对 head 和 tail 以及内部的值加 volatile，保证可见性
         2. 每次更新时，会用 CAS 检查
            1. tail 是否还是 tail
            2. tail 的 next 是否还是 null
      2. BlockingQueue
         1. 内部有多种实现，比如链表和队列
            1. 相同点：
               1. ArrayBlockingQueue 和 LinkedBlockingQueue 都是通过 [Condition](https://javabetter.cn/thread/condition.html) 通知机制来实现可阻塞的插入和删除。
            2. 不同点：
               1. ArrayBlockingQueue 基于数组实现，而 LinkedBlockingQueue 基于链表实现；
               2. ArrayBlockingQueue 使用一个单独的 ReentrantLock 来控制对队列的访问，而 LinkedBlockingQueue 使用两个锁（putLock 和 takeLock），一个用于放入操作，另一个用于取出操作。锁分离，很适合生产和消费频率差不多的场景，这样生产和消费互不干涉的执行，能达到不错的效率。
            3. 实现原理是插入和取出时，都通过 lock 进行上锁，然后用 Condition 来区分全满和全空两种情况来对不满足条件的线程进行 await，获得 CPU 时间之后，完成插入和删除之后，再次调用 condition，来 signal 对应的等待队列
         2. SynchronousQueue
            1. 无容量，当一个线程尝试向 SynchronousQueue 中放入（put）一个元素时，它会阻塞，直到有另一个线程尝试从队列中取出（take）这个元素
            2. 可以实现类似公平锁，也是在内部维护了一个队列
         3. PriorityBlockingQueue
            1. 通过 compare，来实现优先级
            2. 内部是个最小堆
         4. DelayQueue
            1. 要放入 `DelayQueue` 的元素必须实现 `java.util.concurrent.Delayed` 接口。这个接口定义了两个方法：
               1. `long getDelay(TimeUnit unit)`: 返回此对象剩余的延迟时间，以给定的时间单位表示。如果此对象的延迟已过期，则此方法必须返回零或负数。
               2. `int compareTo(Delayed o)`: 将此对象与另一个 `Delayed` 对象进行比较。此方法用于内部排序，以确保队列头部的元素是延迟最短的。通常，如果此对象的延迟时间小于另一个对象的延迟时间，则返回负整数；如果相等，则返回零；如果大于，则返回正整数。
            2. **DelayQueue** **的主要特点**
               1. 无界性：理论上可以存储无限多个元素（受限于系统内存）。
               2. 阻塞性：当尝试从空队列中获取元素，或者队列中所有元素的延迟都尚未到期时，`take()` 方法会阻塞调用线程。
               3. 延迟获取：只有当元素的 `getDelay()` 方法返回小于等于 0 的值时，该元素才能被取出。
               4. 有序性：队列内部会根据元素的延迟时间进行排序，延迟时间最短的元素排在队首。
4. 原子类：内部都是通过调用 unsafe. 来实现的
   1. 使用原子更新字段需要两步：
      1. 通过静态方法 `newUpdater` 创建一个更新器，并且设置想要更新的类和字段；
      2. 字段必须使用 `public volatile` 进行修饰；
   2. 基本类型原子类：
      - `AtomicInteger`: 原子更新 `int` 值。
      - `AtomicLong`: 原子更新 `long` 值。
      - `AtomicBoolean`: 原子更新 `boolean` 值。
   3. 引用类型原子类：
      - `AtomicReference<V>`: 原子更新对象引用。
      - `AtomicStampedReference<V>`: 原子更新带有版本号的对象引用，可以解决 ABA 问题。版本号（stamp）是一个 `int` 值。
      - `AtomicMarkableReference<V>`: 原子更新带有标记位的对象引用。标记位是一个 `boolean` 值。相比 `AtomicStampedReference` 更轻量级，如果只需要一个简单的“已处理”或“未处理”标记。
   4. 数组类型原子类：
      - `AtomicIntegerArray`: 原子更新 `int` 数组里的元素。
      - `AtomicLongArray`: 原子更新 `long` 数组里的元素。
      - `AtomicReferenceArray<E>`: 原子更新对象引用数组里的元素。
   5. 字段更新器原子类 (Updater)：
      - `AtomicIntegerFieldUpdater<T>`: 原子更新指定类的指定 `volatile int` 字段。
      - `AtomicLongFieldUpdater<T>`: 原子更新指定类的指定 `volatile long` 字段。
      - `AtomicReferenceFieldUpdater<T, V, W>`: 原子更新指定类的指定 `volatile` 对象引用字段。
      - 这些 Updater 类使得我们可以在不直接修改已有类代码（不需要让字段本身是 `AtomicInteger` 等类型）的情况下，对其 `volatile` 字段进行原子操作，但字段必须是 `volatile` 且对 Updater 可见。
   6. 累加器 (Adders / Accumulators)：
      - `LongAdder`: 高并发环境下高效的 `long` 类型累加器。
      - `DoubleAdder`: 高并发环境下高效的 `double` 类型累加器。
      - `LongAccumulator`: 更通用的 `LongAdder`，可以自定义累加函数。
      - `DoubleAccumulator`: 更通用的 `DoubleAdder`，可以自定义累加函数。

### List

1. List 接口

   1. 遍历方式
      1. for 循环：可以一边遍历一边修改
      2. foreach（也是迭代器）：最好不要，可能导致迭代器的预期结构与实际结构不同。可能抛出 ConcurrentModificationException** 异常 **
      3. 迭代器：可以用 set 方法来修改值
   2. 删除：都是 remove（index）
      1. 数组和链表就不说了，COWAL 的删除时间取决于复制新数组的时间
2. ArrayList

   1. 底层数据结构
      1. 数组，动态扩容
   2. 扩容：
      1. 检查到 size == capacity 时扩容，扩大到原来的 1.5 倍
         1. 会优先考虑 `Math.max(minCapacity, oldCapacity + (oldCapacity >> 1))` 其中 `minCapacity` 是最小需要的容量（当前 size + 需要添加的元素的数量，通常是 size + 1）， `oldCapacity` 是原来的容量。
         2. 如果新的容量比 Integer.MAX_VALUE - 8 大，则会根据需要的最小容量 minCapacity 来选择是扩容到 Integer.MAX_VALUE 还是 throw OutOfMemoryError (OOM)。
         3. 这里的 `oldCapacity >> 1` 相当于 `oldCapacity / 2`，是一种更高效的位运算
      2. 之后用 Arrays.copyOf() 来复制原数组
   3. 基本方法的实现：
      1. Add 到指定的位置
         1. `add(int index, E element)` 方法会调用到一个非常重要的[本地方法](https://javabetter.cn/oo/native-method.html) `System.arraycopy()`，它会对数组进行复制（要插入位置上的元素往后复制）
      2. remove
         1. remove(index)：也要调用 System.arraycopy 方法将删除位置后面的元素向前移动一位。最后，将数组末尾的元素置为 null，以便让垃圾回收机制回收该元素占用的空间
         2. remove（object）遍历，该方法通过遍历的方式找到要删除的元素，null 的时候使用 == 操作符判断，非 null 的时候使用 `equals()` 方法，然后调用 `fastRemove()` 方法
   4. 为什么线程不安全
      ![](static/KA0obYh0DoAKZJxhumrcXgYwnke.png)
3. LinkedList

   1. 底层数据结构
      1. 双向链表，自带扩容
   2. 扩容
      1. 不用扩容
   3. 为什么线程不安全
      1. 并发修改导致数据丢失或损坏:
         1. 假设线程 A 和线程 B 同时访问同一个 LinkedList 实例，并且都执行 `add(E e)` 方法。
         2. 由于链表是基于节点链接的结构，`add` 操作需要更新节点的引用关系。
         3. 如果 A 线程刚修改完一部分节点引用，还没完全完成整个添加操作时，B 线程又开始进行添加操作，可能会覆盖 A 线程的修改，导致 A 线程要添加的数据丢失，或者链表结构损坏，变得无法遍历。
      2. 迭代器失效 (ConcurrentModificationException) :
         1. 即使你不直接调用 `add` 或 `remove` 方法，如果多个线程同时迭代 LinkedList，并有一个线程进行了结构性的修改（添加、删除元素），那么其他的迭代器可能会变得无效，抛出 `ConcurrentModificationException` 异常。 这是因为迭代器通常会维护一个表示结构修改次数的内部变量，如果这个变量和 LinkedList 自身的修改次数不一致，就会抛出异常。
      3. Get 操作导致数据不一致
         1. 假设线程 A 和线程 B 同时访问同一个 LinkedList 实例，并且通过索引都想 `get` 同一个元素。
         2. 因为 LinkedList 需要遍历到对应的索引位置，假设线程 A 遍历到索引位置了，然后线程 B 此时将这个索引之前的元素给删除了，那么线程 A 再进行 get 操作，拿到的就不是原来索引位置的元素了。

### Queue

1. Deque 接口

   1. LinkedList
   2. ArrayDeque
      1. 底层数据结构：
         1. 循环数组，普通数组 +head 和 tail 来管理对象
      2. 扩容机制：即 `head == tail` 并且数组已非空
         1. 与 ArrayList 相同，不过要重置 head 和 tail
      3. 线程不安全：
         1. 索引修改问题
         2. 扩容问题（和 ArrayList 相同）
2. Queue 接口

   1. PriorityQueue
      1. 底层数据结构：
         1. 底层是一个 二叉堆 (binary heap) ，通常是 最小堆 (min-heap)用一个 数组 来实现的。数组中的元素按照堆的规则进行排列：对于任意节点 `i`，如果它有子节点，那么 `queue[i]` 的值小于或等于（对于最小堆）其子节点 `queue[2*i+1]` 和 `queue[2*i+2]` 的值。
         2. 维护一个 `size` 字段表示队列中元素的数量
      2. 扩容机制：
         1. 数组满的时候，和 ArrayList 相同
      3. 线程不安全：
         1. size 字段的修改
         2. 堆调整操作 (siftUp / siftDown) :
            1. `offer(E e)`: 元素添加到数组末尾（逻辑上是堆的最后一个叶子节点），然后执行 `siftUp` 操作（也叫上滤或 percolate up）来恢复堆属性。`siftUp` 涉及比较和交换元素位置，这是一个多步操作。
            2. `poll()`: 移除堆顶元素（数组的第一个元素），将最后一个元素放到堆顶，然后执行 `siftDown` 操作（也叫下滤或 percolate down）来恢复堆属性。`siftDown` 也涉及比较和交换。
               如果多个线程同时 `offer` 或 `poll`，或者一个 `offer` 一个 `poll`：
            3. 它们可能同时修改 `size` 导致计数错误。
            4. 它们可能同时对数组进行读写和元素交换，导致堆属性被破坏，元素顺序错乱，甚至可能导致错误的元素被返回或重要元素丢失。例如，一个线程正在 `siftUp`，另一个线程可能读取到尚未调整好的中间状态，或者修改了正在被 `siftUp` 过程依赖的元素。
         3. 扩容操作: 和 `ArrayDeque` 类似，扩容时如果其他线程正在进行 `offer` 或 `poll` 操作，它们可能操作的是旧数组，或者在新旧数组拷贝过程中发生数据不一致。
3. Queue 与 Deque 的方法差别

   1. Queue 的常见方法（接口的方法）:尾部添加，头部移除
      - `add(E e)`: 将指定的元素插入此队列中（如果立即可行且不违反容量限制），成功时返回 `true`，如果当前没有可用的空间，则抛出 `IllegalStateException`。
      - `offer(E e)`: 将指定的元素插入此队列中（如果立即可行且不违反容量限制），成功时返回 `true`，如果当前没有可用的空间，则返回 `false`。 （推荐使用 `offer`，因为避免了异常）
      - `remove()`: 获取并移除此队列的头，如果此队列为空，则抛出 `NoSuchElementException`。
      - `poll()`: 获取并移除此队列的头，如果此队列为空，则返回 `null`。 （推荐使用 `poll`，因为避免了异常）
      - `element()`: 获取但不移除此队列的头，如果此队列为空，则抛出 `NoSuchElementException`。
      - `peek()`: 获取但不移除此队列的头，如果此队列为空，则返回 `null`。 （推荐使用 `peek`，因为避免了异常）
   2. Deque 的常见方法
      1. 作为队列：
         - 从头部添加:
           - `addFirst(E e)`: 头部添加元素 (如果队列满了，抛出异常)
           - `offerFirst(E e)`: 头部添加元素 (如果队列满了，返回 false)
         - 从尾部添加:
           - `addLast(E e)`: 尾部添加元素 (如果队列满了，抛出异常) - 等同于 `add(E e)` 和 `offer(E e)` 在 `Queue` 接口中的行为
           - `offerLast(E e)`: 尾部添加元素 (如果队列满了，返回 false) - 等同于 `offer(E e)` 在 `Queue` 接口中的行为
         - 从头部移除:
           - `removeFirst()`: 移除并返回头部元素 (如果队列为空，抛出异常) - 等同于 `remove()` 和 `element()` 在 `Queue` 接口中的行为
           - `pollFirst()`: 移除并返回头部元素 (如果队列为空，返回 null) - 等同于 `poll()` 和 `peek()` 在 `Queue` 接口中的行为
         - 从尾部移除:
           - `removeLast()`: 移除并返回尾部元素 (如果队列为空，抛出异常)
           - `pollLast()`: 移除并返回尾部元素 (如果队列为空，返回 null)
         - 获取头部元素:
           - `getFirst()`: 获取但不移除头部元素 (如果队列为空，抛出异常)
           - `peekFirst()`: 获取但不移除头部元素 (如果队列为空，返回 null)
         - 获取尾部元素:
           - `getLast()`: 获取但不移除尾部元素 (如果队列为空，抛出异常)
           - `peekLast()`: 获取但不移除尾部元素 (如果队列为空，返回 null)
      2. 作为栈：头部插入，头部取出
         - `push(E e)`: 将元素推入栈顶。 相当于 `addFirst(E e)`。 如果 `Deque` 有容量限制，并且已经满了，则抛出 `IllegalStateException`。
         - `pop()`: 移除并返回栈顶的元素。相当于 `removeFirst()`。 如果 `Deque` 为空，则抛出 `NoSuchElementException`。
         - `peek()`: 返回栈顶的元素，但不移除它。相当于 `peekFirst()`。 如果 `Deque` 为空，则返回 `null`。 （推荐使用，防止异常）

### Set

1. HashSet

   1. 底层数据结构：
      1. Hash 表，也就是 `java.util.HashMap` 实例来存储元素的
   2. 扩容和线程安全问题和 HashMap 相同
2. LinkedHashSet

   1. 同上，它在 `HashSet` 的基础上，额外维护了一个双向链表来记录元素的插入顺序。因此，迭代 `LinkedHashSet` 时，元素会按照它们被插入的顺序返回。
3. TreeSet

   1. 同上

### Stack

1. stack 是单独一个类
   1. 底层数据结构:
      由于 `Stack` 继承自 `Vector`，其底层数据结构是一个动态数组 (Object[]) 。`Vector` 内部使用一个名为 `elementData` 的 `Object` 数组来存储元素。
   2. 线程安全的
   3. 性能不好不推荐使用，用 ArrayDeque 替代

### Map

1. HashMap

   1. Hash 底层数据结构
      1. 底层是数组加红黑树和链表
         1. 当链表长度大于 8 时，转化为红黑树
         2. 当链表长度小于 6 时，转换回链表
   2. HashMap 的扩容机制
      1. 默认因子为 0.75，默认大小为 16
         1. 选 0.75 除了性能考虑外，还因为 3/4 与任何 2 的幂次方的积都是整数
      2. 将原来的数组扩大两倍，然后分三种情况，逐个遍历每个桶：
         1. 先 resize，
         2. 桶中只有一个元素：直接 rehash 到新的位置
            1. 在 JDK 8 的新 hash 算法下，数组扩容后的索引位置，要么就是原来的索引位置，要么就是“原索引 + 原来的容量”，遵循一定的规律
         3. 桶中为链表：通过分类 hash(k)&旧长度 == 0 和 ！= 0 的，为 0 则直接移动到新桶的链表中，不为 0 则放入对应位置
         4. 桶中为红黑树：红黑树执行 rehash，分类过程与链表相同，完成后执行监测，如果小于 6，则取消树化
   3. HashMap 与 HashTable 与 ConcurrentHashMap 的区别
      1. 线程安全：
         1. HashMap：不安全
            1. JDK8 之前，拉链法是通过头查的方式进行的，多线程情况下扩容会形成死循环
            2. 两个线程同时 put 到同一个位置，会导致一个值丢失，因为 put 之前已经判断当前位置上没有值了
         2. HashTable：基于 synchronize，安全
         3. ConcurrentHashMap：CAS+ 分段锁的方式，安全
            1. 如果目标位置为空，则用 CAS 更新
            2. 如果目标位置不为空，则 synchronize 锁住，然后更新
            3. 如果目标位置为 MOVED，即正在扩容，那么调用 helpTransfer 方法来协助扩容
      2. 是否允许 null 值：
         1. HashMap：都行
         2. 其他俩：都不行
      3. 底层实现：
         1. HashMap 和 ConcurrentHashMap ： 数组 + 链表/红黑树
         2. HashTable：数组 + 链表
   4. concurrentHashMap 的扩容机制
      1. 在达到扩容条件后，开始扩容，并且通过 transferIndex 指示当前未被处理的槽位，线程通过 CAS 递减来领取一段槽位进行扩容，同时对这段加锁保证只有一个线程处理他。新的线程过来发现在扩容，会背抓来辅助扩容
2. LinkedHashMap：通过维护一个双向链表来记录元素的插入顺序或访问顺序。非常适合用来实现 LRU (Least Recently Used) 缓存

   1. 底层数据结构：
      1. 基本存储结构是一个哈希表（数组 + 链表/红黑树），与 `HashMap` 类似
      2. `LinkedHashMap` 额外维护了一个贯穿其所有条目（Entry）的双向链表。这个链表定义了迭代映射的顺序。
         1. `Entry` 结构：`LinkedHashMap` 的每个内部条目（`LinkedHashMap.Entry`）除了包含键（key）、值（value）、哈希值（hash）和指向桶内下一个节点的指针（`next`，用于解决哈希冲突）之外，还包含两个额外的指针：`before` 和 `after`。这两个指针用于维护双向链表。
         2. `head` 和 `tail` ：`LinkedHashMap` 内部有两个特殊的指针，`head` 指向链表的头部，`tail` 指向链表的尾部
   2. 顺序模式：
      1. 插入顺序（默认） ：默认情况下，迭代器将按照键插入映射的顺序返回条目。新插入的条目会被添加到双向链表的尾部。
      2. 访问顺序：如果在构造 `LinkedHashMap` 时将 `accessOrder` 参数设置为 `true` (例如 `new LinkedHashMap(initialCapacity, loadFactor, true)`), 那么每次调用 `get` 方法访问一个条目时，该条目会被移动到双向链表的尾部。这使得 `LinkedHashMap` 非常适合用来实现 LRU (Least Recently Used) 缓存。
   3. 与 hashmap 相同
   4. 为什么线程不安全
      1. 除了 hashMap 的 put 问题之外，还有双向链表的维护问题
3. TreeMap

   1. 底层数据结构：
      1. `TreeMap` 的核心是一个红黑树。红黑树是一种自平衡的二叉查找树，它通过特定的着色规则（每个节点是红色或黑色）和旋转操作来确保树在插入和删除操作后保持大致平衡，从而保证了 `get`, `put`, `remove` 等操作的时间复杂度为 O(log⁡n)_O_(log_n_)。
   2. 扩容机制
      1. 不需要扩容
   3. 为什么线程不安全：
      1. 链表的安全问题

### 工具类

1. Collections 类：用于操作集合框架中的对象，不能用于操作基本数据类型的数组。

   1. 常用方法和原理
      1. sort：默认升序
         1. 调用的 List.sort 方法
            1. `ArrayList` 及其底层是数组，当元素数量小于等于 `INSERTIONSORT_THRESHOLD` (通常为 7)，使用插入排序； 否则，会根据元素排列是否满足单调性，选择使用 TimSort 或者 LegacyMergeSort。
               1. `TimSort`: 一种混合排序算法，结合了归并排序和插入排序的优点。 它是自适应的，可以利用数据中已经存在的有序段，从而提高效率.JDK7 之后 ArrayList 使用的排序方式。
               2. `LegacyMergeSort`: 经典的归并排序实现。
            2. `LinkedList` : 使用归并排序。
      2. binarySearch
         1. `binarySearch(List<? extends Comparable<? super T>> list, T key)` : 在已排序的列表中使用二分查找搜索指定元素。
            1. 原理: 二分查找算法，前提是列表必须已经排序。 时间复杂度为 O(log n)。
         2. `binarySearch(List<? extends T> list, T key, Comparator<? super T> c)` : 根据提供的 `Comparator` 在已排序的列表中使用二分查找搜索指定元素。
            1. 原理: 与上面的类似，但使用传入的 `Comparator` 来比较元素。
2. Arrays 类：用来操作数组(基本类型或对象数组)

   1. `sort()` 方法（排序）
      1. 作用： 对数组进行排序。`Arrays` 类提供了多种 `sort()` 方法的重载版本，可以对不同类型的数组进行排序 (`int`, `long`, `float`, `double`, `Object` 等)。
      2. 实现原理：
         1. 基本类型数组： 对于基本类型数组（例如 `int[]`, `double[]`），`Arrays.sort()` 主要使用快速排序（QuickSort） 算法。为了处理小数组和部分有序的数组，`sort()` 内部还会根据数组的大小和状态选择合适的排序算法，可能还会用到插入排序（Insertion Sort） 。 快速排序的总体思路是，选择一个 pivot(基准值)，将数组分成两部分，一部分小于 pivot，一部分大于 pivot，然后对这两部分递归地进行快速排序。
            1. 快速排序的优点： 平均时间复杂度为 O(n log n)，效率较高。
            2. 快速排序的缺点： 最坏情况下时间复杂度为 O(n^2)（例如，输入数组已经排序好的情况）。
            3. `Arrays` 的优化： Java 的 `Arrays.sort()` 实现中会尽力避免快速排序的最坏情况，会采用一些优化手段，例如随机选择基准值，或者使用三向切分等策略。
         2. 对象类型数组： 对于对象数组（例如 `String[]`），`Arrays.sort()` 使用归并排序（MergeSort） 算法。 归并排序将数组递归地分成两半，分别进行排序，然后将排序好的两半合并成一个有序数组。
            1. 归并排序的优点： 时间复杂度稳定在 O(n log n)，并且是稳定的排序算法（相等元素的相对位置不会改变）。
            2. 归并排序的缺点： 需要额外的空间来进行合并操作。
   2. `binarySearch()` 方法
   3. `fill()` 方法
   4. `copyOf()` 和 `copyOfRange()` 方法（复制）
   5. `equals()` 和 `deepEquals()` (比较)
      1. 作用: 比较两个数组是否相等。`equals()` 用于比较一维数组，检查的是两个数组的长度和每个位置的元素是否相等。 `deepEquals()` 用于比较多维数组，会递归地比较数组中的子数组。
   6. `toString()` 和 `deepToString()` 方法 (转换为字符串)
      1. 作用： 将数组转换为字符串表示形式。`toString()` 用于一维数组，返回一个包含数组元素的字符串，元素之间用逗号和空格分隔。 `deepToString()` 用于多维数组，递归地将多维数组转换为字符串。
      2. 实现原理： 遍历数组，将每个元素转换为字符串，并将它们连接成一个字符串，用特定分隔符分隔
   7. `asList()` 方法 (转换为 List)
      1. 作用： 将数组转换为 `List` 集合。
      2. 实现原理： 返回一个由指定数组支持的固定大小的 `List`。 这意味着你不能向这个 `List` 中添加或删除元素，否则会抛出 `UnsupportedOperationException`。 这个 `List` 实际上是对原始数组的一个视图，对 `List` 的修改会反映到原始数组上。
         1. 注意事项： 返回的 `List` 不是 `java.util.ArrayList`，而是 `Arrays` 类的一个内部类 `ArrayList`，它并不支持所有 `List` 的操作。
3. 相互转换：

   - `Arrays.asList(T... a)`: 可以将一个数组转换（或视为）一个 `List`。这个 `List` 是固定大小的，并且其修改会影响到底层的数组。它更像是一个数组的适配器，使其能够使用 `List` 的一些接口，但不能进行结构性修改（如添加或删除元素）。
   - `Collection.toArray()`: 集合接口 (`java.util.Collection`) 定义了 `toArray()` 方法，可以将集合转换为数组

### 不同接口

1. Iterator 与 Iterable 有什么区别
   1. Iterator 迭代器是个接口，Iterable 也是个接口。前者表示迭代的方式，后者表示这个类可以迭代，可以用 for-each 方法
   2. `Iterator` 接口提供了遍历集合元素的标准方式
      - 核心方法：
        - `hasNext()`: 如果迭代还拥有更多元素，则返回 `true`。
        - `next()`: 返回迭代的下一个元素，并将迭代器的指针向后移动。如果已经没有下一个元素了，调用此方法会抛出 `NoSuchElementException`。
        - `remove()`: (可选操作) 移除迭代器最后一次返回的元素。如果该迭代器不支持 `remove` 操作，则会抛出 `UnsupportedOperationException`。每次调用 `next()` 后，最多只能调用一次 `remove()`。
      - Iterable 对象中获得 Iterator： `Iterator<String> iterator = names.iterator();`

## JUC

### 多线程

1. 线程与进程的区别

   1. 本质的区别是是否拥有独立的地址空间和系统资源
      1. 进程有独立的空间，进程之间互不干扰，是操作系统分配资源的单位
      2. 线程共享进程的空间，线程崩溃会影响进程的运行，是操作系统调度的单位，是分配 CPU 时间的单位
2. Java 的线程是采用的原生线程模型，意思是当 JVM 创建一个新线程的时候，会请求操作系统创建一个新线程来执行他
3. 安全性：

   1. 原子性：同一时刻，只能有一个线程操作数据
      1. atomic 包
      2. synchronize 锁
   2. 可见性：一个线程对数据的操作对其他线程都可见
      1. volatile 关键字
      2. synchronize 锁
   3. 有序性：
      1. 一个线程观察其他线程中的指令执行结果是否有序
      2. happens-before 原则
4. 如何创建一个线程

   1. 本质上都是用 Thread 类，重写 run 方法，用 start 方法启动
   2. 继承 Thread 类
   3. 实现 Runnable()接口之后，重写 run 方法，在 Thread 类的构造函数中传入这个类
   4. 实现 Callable()接口，可以获得返回值，返回值在 Future 类里，用 submit 提交 Callable
      1. Future 的 get 方法会造成阻塞，因为 FutureTask 这个具体的实现类是实现的 AQS，内部会用 LockSupport 的 park 来 wait 线程
   5. 用线程池，submit 实现了 runnable 接口的类
5. 如何停止一个线程的执行

   1. 调用 Interrupt 命令
   2. 使用 volatile 的一个共享标志位，让线程主动退出
   3. 用线程池的中断机制，通过 Future.cancle 来退出
6. Java 线程的状态

   1. New
      1. 创建了但还没调用 start 方法
   2. Runnable
      1. Running
         1. 正在使用 CPU 资源
      2. Ready
         1. 等待分配 CPU 资源
   3. Blocking
      1. 在 Java 中，线程状态 `BLOCKED` 特指线程在等待获取一个监视器锁 (monitor lock) 的情况
      2. 阻塞中，比如等待锁释放
      3. 会在锁释放之后自动被唤醒
   4. Waiting
      1. 进入等待状态，其他的线程 notify 了才会被唤醒
   5. Timed_waiting
      1. 有超时的等待状态
   6. terminated
      1. 线程结束
7. wait、notify、notyfyAll

   1. 这些方法都是 object 的方法，不是线程的
   2. 要使用这些方法，首先得获得某一个对象的监视器锁，监视器锁是每一个对象都有的，线程进入 synchronize 块，获得监视器锁之后，调用对象的这些方法，来让持有锁的线程进行对应的操作
      1. `wait()` :
         - 前提：一个线程必须持有该对象的监视器锁才能调用该对象的 `wait()` 方法。如果当前线程没有持有锁而调用 `wait()`，会抛出 `IllegalMonitorStateException`。
         - 行为：
           1. 当前线程释放它所持有的该对象的监视器锁。这是非常重要的一点，因为它允许其他线程获取该对象的锁，从而有机会改变条件。
           2. 当前线程进入该对象的等待队列 (wait set) ，并进入等待状态 (WAITING 或 TIMED_WAITING) ，暂停执行。
           3. 线程会一直等待，直到以下情况之一发生：
              - 另一个线程在该对象上调用 `notify()`。
              - 另一个线程在该对象上调用 `notifyAll()`。
              - 另一个线程中断 (interrupt) 当前线程 (`Thread.interrupt()`)。这种情况下会抛出 `InterruptedException`。
              - 如果调用的是 `wait(long timeout)` 或 `wait(long timeout, int nanos)`，等待超时。
              - 虚假唤醒 (Spurious Wakeup) ：线程可能在没有 `notify()`, `interrupt()` 或超时的情况下被唤醒。这是非常罕见但可能发生的情况。
         - 唤醒后：当线程被唤醒后，它并不会立即继续执行。它会首先尝试重新获取该对象的监视器锁。只有成功获取锁之后，它才能从 `wait()` 方法返回并继续执行。
      2. `notify()` :
         - 前提：一个线程必须持有该对象的监视器锁才能调用该对象的 `notify()` 方法。否则，抛出 `IllegalMonitorStateException`。
         - 行为：
           1. 从该对象的等待队列中唤醒一个正在等待的线程。具体唤醒哪个线程是不确定的（取决于 JVM 的实现）。
           2. 被唤醒的线程并不会立即执行，它需要去竞争该对象的锁。
           3. 调用 `notify()` 的线程并不会立即释放锁，它会继续执行同步代码块中的剩余语句，直到它退出同步代码块或方法，才会释放锁。
      3. `notifyAll()` :
         - 前提：与 `notify()` 相同，调用线程必须持有该对象的监视器锁。
         - 行为：
           1. 从该对象的等待队列中唤醒所有正在等待的线程。
           2. 被唤醒的所有线程同样不会立即执行，它们都需要去竞争该对象的锁。只有一个线程能成功获取锁并继续执行，其他线程则继续阻塞等待锁。
           3. 调用 `notifyAll()` 的线程也不会立即释放锁，行为与 `notify()` 类似。
   3. 它们如何影响线程？
      - `wait()` : 使当前线程释放锁并进入等待状态，暂停执行。
      - `notify()` / `notifyAll()` : 唤醒一个或所有在该对象上等待的线程，使它们从等待状态变为可运行状态 (Runnable)，准备竞争锁。
   4. **synchronized** **和** **wait/notify** **的关系**
      1. 必须在同步块内: `wait()`, `notify()`, `notifyAll()` 必须在它们所操作的对象的 `synchronized` 方法或代码块内调用。这是因为：
         - 避免竞态条件: 如果没有锁的保护，一个线程可能在检查条件（例如 `while (list.isEmpty())`）之后、调用 `wait()` 之前，另一个线程已经改变了条件并调用了 `notify()`。这个 `notify()` 信号就会丢失，导致前者永久等待。
         - 锁的原子操作: `wait()` 需要原子地释放锁并进入等待状态。`notify()`/`notifyAll()` 也与锁状态紧密相关。`synchronized` 提供了这种原子性保证。
         - `IllegalMonitorStateException` : JVM 强制要求这种做法。如果一个线程没有持有对象的锁就尝试调用这些方法，JVM 会抛出此异常。
      2. 锁对象一致性: `wait()`, `notify()`, `notifyAll()` 调用的对象，必须是 `synchronized` 关键字锁定的那个对象。
         - `synchronized(obj) { obj.wait(); }` 是正确的。
         - `synchronized(obj) { anotherObj.wait(); }` 是错误的（会导致 `IllegalMonitorStateException`，因为当前线程持有 `obj` 的锁，而不是 `anotherObj` 的锁）。
         - 在一个对象的 `synchronized` 实例方法中，`this.wait()` (或直接 `wait()`) 是正确的，因为实例方法默认锁住 `this` 对象
8. Blocking 与 wait 的区别

   1. blocking 是在试图获取 synchronize 锁时
      1. 阻塞：
         - `synchronized` 的情况: JVM 会自动处理线程进入阻塞状态。 具体来说，当一个线程遇到 `synchronized` 关键字修饰的代码块或方法，它会尝试获取与该对象关联的 monitor 锁。 如果锁已经被其他线程持有，JVM 会将该线程放入该对象的 _等待队列_ 中，并将其状态变为 `BLOCKED`。
         - `java.util.concurrent` 的情况: 当线程调用 `lock()` 方法，而锁已经被占用时，锁的实现（比如 `ReentrantLock`）会负责将线程放入阻塞队列，使其状态为 blocked。 和 `synchronized` 不同， 使用 `Lock` 接口允许你尝试非阻塞地获取锁 (通过 `tryLock()`)。

      - 唤醒：
        - `synchronized` 的情况: 当持有 monitor 锁的线程 退出 了 `synchronized` 代码块或方法时，JVM 会从等待队列中挑选一个线程（选择的策略取决于 JVM 的实现，但不保证公平），将其唤醒，让它尝试重新获取锁。被唤醒的线程会再次尝试获取锁，如果成功，则继续执行；否则，它可能再次被阻塞，虽然这种情况发生的概率较低，但理论上存在。
        - `java.util.concurrent` 的情况:
          - `unlock()` 方法: 持有锁的线程调用 `unlock()` 方法释放锁时，锁的实现会负责唤醒阻塞队列中的一个或多个线程。一般来说，只有一个线程会被唤醒，具体唤醒哪个线程取决于锁的公平性策略。
          - `Condition.signal()` 或 `Condition.signalAll()`: `java.util.concurrent` 包中的 `Condition` 对象（与 `Lock` 关联）允许线程在特定条件下等待。 当一个线程调用了 `await()` 方法，它会被放入 `Condition` 对象的 _等待队列_ 中。 其他线程可以通过调用 `signal()` (唤醒一个等待的线程) 或 `signalAll()` (唤醒所有等待的线程) 来唤醒这些等待的线程。被唤醒的线程会尝试重新获取与 `Condition` 关联的锁。
          - 中断: 虽然不建议，但是被阻塞的线程也可能因为收到中断信号 (`Thread.interrupt()`) 而被唤醒。 不过，在这种情况下，线程通常会抛出 `InterruptedException` 异常，需要程序处理。
   2. blocking 状态下不会消耗 CPU 资源
9. sleep 与 wait 的区别

   1. 锁释放
      1. sleep 进入 timed_waiting 状态，不会释放掉锁，但是会释放掉 CPU 资源
      2. wait 会释放掉锁
   2. 使用条件：
      1. sleep 可以在任意情况下使用
      2. wait 必须在锁中使用
         1. `wait()`, `notify()`, 和 `notifyAll()` 方法用于线程之间的协作，这些方法是 `java.lang.Object` 类的方法，它们必须在同步块或者同步方法中使用
         2. 如果不在同步块中，那么线程的 notify 可能发生在线程的 wait 之前，这样线程就会永远 wait
10. 不同的线程之间如何通信

    1. 通过 static volatile 的静态变量进行
    2. 通过 同一个监视器锁的 wait 和 notify 进行
    3. 用 Lock 类和 Condition 方法
11. 父子线程间的通信

    1. 可以用线程安全的类
    2. 可以用 inheritableThreadLocal 进行，会复制父线程的 ThreadLocal

### 内存模型

1. MESI 模型

   1. 当共享的变量被修改了，会通知其他 CPU 将该变量的缓存行设置为无效状态
   2. 解决的是多核 CPU 之间的缓存问题
2. JMM 模型

   1. 模型内容：
      ![](static/TpLSbmtwHopQpjxKBN8cDEglnyg.png)
      1. 所有的共享变量都存在主存中。
      2. 每个线程都保存了一份该线程使用到的共享变量的副本。
      3. 如果线程 A 与线程 B 之间要通信的话，必须经历下面 2 个步骤：
         1. 线程 A 将本地内存 A 中更新过的共享变量刷新到主存中去。
         2. 线程 B 到主存中去读取线程 A 之前已经更新过的共享变量。
   2. 解决的是多个线程之间的一致性问题
   3. 目标：
      1. 原子性：
         1. 可实现：synchronize
      2. 内存可见性：
         1. 某一个变量在多线程中的修改可见性
      3. 有序性：
         1. 可实现：synchronize、volatile
            1. volatile 通过插入内存屏障来禁止指令重排序
            2. synchronize 保证只有一个线程执行
   4. 问题分析：
      1. 指令重排序：
         1. 目标是为了优化运行速度，减少停顿。重排序可以保证单线程下串行语义一致性，但是无法满足多线程下的一致性
         2. 重排序类型：
            1. 编译器重排序
            2. 内存重排序
            3. 指令优化重排序
               1. 处理器改变没有依赖关系的操作的顺序
   5. JMM 与 happen-before
      1. happen-before 是指，A 在 B 之前发生， 那么 A 的操作结果对 B 可见，且 A 发生在 B 之前
         1. 只要满足这两条规则，JMM 就允许进行重排序
      2. happens-before 是通过 volatile 等方法实现的
         - 在单个线程内部，程序顺序规则提供了基本的 happens-before 保证。
         - 当涉及到多个线程之间的交互和共享数据时，如果你希望一个线程的操作结果对另一个线程可见，并且保证一定的执行顺序，那么你就需要使用像 `volatile`、`synchronized` (或者 `java.util.concurrent` 包下的更高级同步工具) 这样的机制来显式地建立跨线程的 happens-before 关系。
3. volatile 关键字

   1. 这个关键字会通过插入读写屏障的方式，来禁止指令重排序。意思是，写这个变量之前，代码中这个变量之前的全部操作都必须被执行了，且变量全部被写入主存。读这个变量时，所有的线程都是直接从主存中读取这个变量

### 锁

![](static/R6TvbCg6Fo1T6vxlRgxcKP3rnQh.png)

1. 结合 JVM 讲讲为什么单机单实例可用 synchronize 锁，多实例不行。

   1. 因为 synchronize 锁的实现依赖于对象头中的 mark word，多实例的情况下，不同进程之间堆空间不共用
2. synchronize 锁是怎么实现的，可以锁哪些，是怎么锁的，结合 JMM 和 JVM 讲讲。

   1. 同步锁是通过检查对象头上的 mark word 中的线程 ID 和上锁次数来实现的，synchronize 是重入锁也是依赖于这个机制，同一线程多次获取锁，计数器加一，解锁要让计数器归 0。锁只有锁对象和锁实例两种，一种是到元空间的对象上加锁，一种是到堆的实例上加锁。获取锁和释放锁时都会触发内存屏障，将共享内存中的内容刷新到栈帧中，并在释放锁之后刷新回主内存。
      1. 如何知道要不要检查锁
         1. synchronize 会自动添加到字节码中
   2. 监视器锁
      1. 内部可以抽象的理解为由 4 大部分组成：
         1. owner：目前持有锁的线程
      2. 阻塞队列：获取锁失败的线程，被放入阻塞队列中，进入 blocking 状态
      3. wait 队列：目前持有锁的线程 wait 了，释放这个监视器锁，并且将自己加入 wait 队列
      4. 重入计数器
3. 讲讲锁升级流程

   1. 从无锁到偏向锁到轻量锁到重量锁
      1. 偏向锁会在 mark word 里记录线程 ID，允许同一 ID 重复进入，如果有不同 ID 来竞争，那么在安全点退出偏向锁，膨胀成轻量锁
      2. 轻量锁状态下，线程会先复制对象的 mark land 到自己的栈帧里，然后采用 CAS 的方式将 mark land 改为指向自己的 copy 的指针，得不到就自旋，长时间自旋则膨胀为重量锁
         1. CAS 的底层是通过硬件原子命令来实现的，`LOCK CMPXCHG` 指令的原子性是通过以下机制保证的：
            - 独占访问: `LOCK` 前缀确保了在比较和交换操作执行期间，当前 CPU 核心对目标内存地址 (或缓存行) 拥有独占访问权，防止其他 CPU 核心同时修改该内存地址。
            - 硬件保证: 比较和交换操作是由 CPU 硬件原子地执行的，不会被中断。 这意味着，即使在多线程并发访问的情况下，`LOCK CMPXCHG` 指令也能保证只有一个线程能够成功地修改目标内存地址，从而避免了数据竞争和不一致性。
            - 缓存一致性协议: 缓存一致性协议确保了多个 CPU 核心缓存中的数据保持一致，即使在多个核心同时访问同一块内存的情况下，也能保证数据的正确性。
      3. 重量锁会创建 C++ 的 monitor 类，将等待的线程都放到 Entry set 队列中。内部有两个队列
         - Entry Set (入口集 / 竞争队列) :
           - 当多个线程同时竞争同一个对象的监视器锁时，未能成功获取锁的线程会被放入这个集合中。
           - 这些线程处于 `BLOCKED` 状态，等待锁的释放。
           - 是的，这个队列主要是在重量级锁的场景下由 JVM 和操作系统层面管理的。轻量级锁和偏向锁有其自身的优化机制，不直接使用这种显式的、可能涉及操作系统互斥量（mutex）的队列。
         - Wait Set (等待集) :
           - 当一个线程已经持有了对象的监视器锁，但在同步代码块中调用了该对象的 `wait()` 方法时，该线程会释放持有的锁，并进入该对象的 Wait Set 中。
           - 进入 Wait Set 的线程状态会变为 `WAITING` 或 `TIMED_WAITING` (如果调用的是 `wait(long timeout)` 方法)。
           - Wait Set 也是与对象监视器 (Monitor) 关联的。
4. synchronize 与 reentryLock 的区别

   1. 公平锁/非公平锁：
      1. S 只能是非公平锁，R 两个都行
   2. 竞争：
      1. S 在获取竞争期间，只能阻塞等待
      2. R 可以通过 tryLock 操作来实现一定时间内重试，然后失败
5. ReenrryLock 为什么用 synchronize 不用 reentryLock

   1. 因为在优化之后，锁只针对单个 node，并发的可能性减小，synchronize 升级的可能性降低，使两者加锁性能差不多
   2. S 不用手动管理，R 需要自己去操作加锁解锁
   3. S 会不断自旋，不会导致线程挂起。R 会导致线程挂起，这样会增加线程切换的开销
   4. R 是独立的对象，内存消耗也会大一些

### AQS

1. 实现：

   1. AQS 内部维护了一个 Node 节点构成的 FIFO 队列（同步队列），和一个 int 类型的 state
      1. state = 1 表示该锁已经被占有了，state 的更新通过 CAS 完成，也是继承了 unsafe 类的
2. AQS 提供两种模式

   1. 共享锁
   2. 排他锁
3. Condition 与 AQS 的锁配合使用

   1. 在 lock 之后，condition 可以调用 await 方法把线程加入这个 condition 的等待队列中，这是一个单向链表，FIFO
   2. signal 可以把头部的转移到 AQS 的同步队列中去，进行 CAS 获取锁
4. LockSupport

   1. 这是一个静态类，AQS 和 Condition 让线程 wait 都是通过这个类的 park 和 unpark(目标线程)方法

### ThreadLocal

1. ThreadLocal 是在堆上创建的一个类，在他的 set 和 get 方法里，他会读取当前线程（被 new 出来的 Thread 类，在堆上），检查当前线程 Thread 的内部类 ThreadLocalMap 是否存在，不存在就 new 一个，然后再在其中将自己的弱引用设置为 key，set 设置的值作为 value，这样当线程中不再持有这个 ThreadLocal（例如局部代码块执行完毕了），那么这个 ThreadLocal 就只剩下虚引用了，在下次 GC 的可达性分析中，就不会再读取到他，也就是说会被回收。然后 Map 中的 Key 变为 null，在下次对 map 进行操作的时候，扫描 null 的 Key 进行删除

   1. 当 ThreadLocal 对象本身没有其他强引用指向它，并且发生 GC 时，ThreadLocal 对象的 `key` 会被回收。 问题就在于，即便 `key` 被回收了，ThreadLocalMap 中对应的 `<key, value>` 节点 仍然存在，而且 `value` 有可能持有大量的数据。 因为 `value` 仍然被 ThreadLocalMap 中的 `Entry` 对象强引用，从而导致 `value` 对象无法被回收。这就是 ThreadLocal 内存泄漏的根源。
2. `Thread` 对象与 JVM 栈的关系：

   - `Thread` 对象是线程的抽象：堆上的 `Thread` 对象可以看作是操作系统层面线程在 Java 语言层面的一个代表或句柄。它包含了线程的属性（如线程 ID、名称、状态、优先级等）以及与线程控制相关的方法（如 `start()`, `join()`, `interrupt()` 等）。
   - JVM 栈是线程执行的场所：JVM 栈是线程实际执行方法调用的地方。`Thread` 对象本身并不直接包含正在执行的代码或局部变量，这些都存在于其对应的 JVM 栈的栈帧中。
   - 关联：JVM 内部机制会将堆上的 `Thread` 对象与其对应的操作系统线程以及其私有的 JVM 栈关联起来。当你调用 `Thread.currentThread()` 时，JVM 能够知道当前正在执行代码的线程是哪一个，并返回堆上对应的那个 `Thread` 对象
3. 不同的子线程可以使用相同的 ThreadLocal 对象作为 Map 的 key

   1. 例如使用静态变量
   2. ThreadLocal 的泛型只是规定 set 传入值的类型

### 数据库原子操作

![](static/QLeYb4ByjoDac5xOewwc7Qiwnjb.png)

1. update 操作会加 X 锁，此时不会产生并发问题，可以直接更新收藏数、参与人数等

### 线程池

![](static/MbjRbzt0roXtq6xLIFGcnjVrnId.png)

1. 线程池的七大核心参数：
   1. corePoolSize：线程池中用来工作的核心线程数量。
   2. maximumPoolSize：最大线程数，线程池允许创建的最大线程数。
   3. keepAliveTime：超出 corePoolSize 后创建的线程存活时间或者是所有线程最大存活时间，取决于配置。
   4. unit：keepAliveTime 的时间单位。
   5. workQueue：任务队列，是一个阻塞队列，当线程数达到核心线程数后，会将任务存储在阻塞队列中。
      1. ArrayBlockingQueue
      2. LinkedListBlockingQueue
      3. PriorityBlockingQueue
      4. SynchronousQueue
   6. threadFactory ：线程池内部创建线程所用的工厂。
   7. handler：拒绝策略；当队列已满并且线程数量达到最大线程数量时，会调用该方法处理任务
      1. AbortPolicy：丢弃任务，抛出运行时异常
         1. 线程池创建的时候，如果不指定拒绝策略就默认是 AbortPolicy 策略。
      2. CallerRunsPolicy：由提交任务的线程来执行任务
      3. DiscardPolicy：丢弃这个任务，但是不抛异常
      4. DiscardOldestPolicy：从队列中剔除最先进入队列的任务，然后再次提交任务
2. 线程池内部的 5 种状态
   - RUNNING：线程池创建时就是这个状态，能够接收新任务，以及对已添加的任务进行处理。
   - SHUTDOWN：调用 shutdown 方法，线程池就会转换成 SHUTDOWN 状态，此时线程池不再接收新任务，但能继续处理已添加的任务到队列中。
   - STOP：调用 shutdownNow 方法，线程池就会转换成 STOP 状态，不接收新任务，也不能继续处理已添加的任务到队列中任务，并且会尝试中断正在处理的任务的线程。
   - TIDYING：SHUTDOWN 状态下，任务数为 0， 其他所有任务已终止，线程池会变为 TIDYING 状态；线程池在 SHUTDOWN 状态，任务队列为空且执行中任务为空，线程池会变为 TIDYING 状态；线程池在 STOP 状态，线程池中执行中任务为空时，线程池会变为 TIDYING 状态。
   - TERMINATED：线程池彻底终止。线程池在 TIDYING 状态执行完 `terminated()` 方法就会转变为 TERMINATED 状态。
3. 线程池参数应该怎么设置
   1. 最大线程数和核心线程数
      1. 理论上是可以根据 IO 和 CPU 密集型来分，但是一个程序中很可能不止一个线程池，所以一般是看经验值，或者通过暴露核心参数，形成动态线程池
      2. 动态线程池：
         1. 三种：
            1. 人工
            2. 根据 CPU 负载
            3. 根据时间负载
         2. 为什么目前的线程数大于核心线程数的时候调整不生效
            - 当你将 `corePoolSize` 调小时，`ThreadPoolExecutor` 不会立即终止正在运行的或已创建的核心线程来匹配新的、更小的 `corePoolSize`。这些线程会继续运行，直到它们自然结束任务。
            - 如果 `allowCoreThreadTimeOut` 为 `false`（默认值），即使这些“超额”的核心线程变为空闲，它们也不会被回收。因此，你会观察到线程数仍然大于新的 `corePoolSize`。调整 `corePoolSize` 更多的是影响未来线程的创建和保留策略，以及在 `allowCoreThreadTimeOut(true)` 时对空闲核心线程的回收策略。它不是一个强制立即缩减线程数的命令。
   2. 阻塞队列的选择：
      1. ArrayBlockingQueue 或有界的 LinkedBlockingQueue
         1. 前者一把锁，后者头部和尾部各一把锁，吞吐量更高
   3. 线程存活时间
      1. 系统资源：
         - 如果系统资源（特别是内存）比较紧张，应设置较短的 `keepAliveTime`，以便更快地回收空闲线程，减少资源占用。
         - 如果系统资源充足，可以适当延长 `keepAliveTime`，以减少线程创建和销毁的开销，提高响应速度，因为线程可以被复用。

      - CPU 密集型 vs IO 密集型任务： 对于 IO 密集型任务，线程大部分时间在等待 IO 操作，可以配置更多的线程数，`keepAliveTime` 的影响相对较小，但仍需考虑资源。对于 CPU 密集型任务，线程数不宜过多（通常是 CPU 核心数 +1 或 +2），`keepAliveTime` 可以根据任务的突发性来调整。
   4. 拒绝策略
      1. 任务的重要性：
         - 关键任务： 如果任务非常重要，绝对不能丢失，那么 `AbortPolicy` (然后由调用者处理) 或 `CallerRunsPolicy` 可能是较好的选择。`CallerRunsPolicy` 能保证任务被执行，但会影响提交者的性能。
         - 非关键任务： 如果任务丢失是可以接受的，可以考虑 `DiscardPolicy` 或 `DiscardOldestPolicy`。
      2. 系统期望的行为：
         - 快速失败： 如果希望系统在过载时能快速失败并通知调用方，选择 `AbortPolicy`。
         - 减速运行： 如果希望通过减慢任务提交速度来应对过载，选择 `CallerRunsPolicy`。
         - 静默处理： 如果不希望过载影响到调用方（但可能丢失任务），选择 `DiscardPolicy` 或 `DiscardOldestPolicy`
4. Executors 可以创建哪 5 个默认线程池
   1. `Executors.newFixedThreadPool(int nThreads)`:ExecutorService executor = Executors.newFixedThreadPool(10);
      1. 创建一个固定大小的线程池。
      2. 核心线程数和最大线程数都是 `nThreads`。
      3. 线程空闲时不会被回收，始终保持指定的线程数。
      4. 使用 `LinkedBlockingQueue` 作为阻塞队列 (无界队列)。
      5. 适用于任务量稳定，需要快速响应的场景。
      6. 风险： `LinkedBlockingQueue` 无界队列可能导致 OOM。
   2. `Executors.newSingleThreadExecutor()`:ExecutorService executor = Executors.newSingleThreadExecutor();
      1. 创建一个单线程的线程池。
      2. 相当于 `newFixedThreadPool(1)`。
      3. 保证所有任务按照提交顺序依次执行。
      4. 使用 `LinkedBlockingQueue` 作为阻塞队列 (无界队列)。
      5. 适用于需要顺序执行的任务，例如串行执行某些操作。
      6. 风险： `LinkedBlockingQueue` 无界队列可能导致 OOM。
   3. `Executors.newCachedThreadPool()`:ExecutorService executor = Executors.newCachedThreadPool();
      1. 创建一个可缓存的线程池。
      2. 核心线程数为 0，最大线程数为 `Integer.MAX_VALUE` (几乎无限)。
      3. 如果有空闲线程 (默认空闲 60 秒)，则会复用空闲线程执行新任务。 如果没有空闲线程，则会创建新线程。
      4. 当线程空闲时间超过指定时间 (默认 60 秒) 时，会被回收。
      5. 使用 `SynchronousQueue` 作为阻塞队列 (不存储任务，直接提交给线程)。
      6. 适用于执行大量短期异步任务的场景。
      7. 风险： 可能创建大量线程，导致 CPU 占用率过高或 OOM。
   4. `Executors.newScheduledThreadPool(int corePoolSize)`:ScheduledExecutorService executor = Executors.newScheduledThreadPool(5);// 延迟 1 秒执行 executor.schedule(() -> System.out.println("延迟执行"), 1, TimeUnit.SECONDS);// 周期性执行，初始延迟 2 秒，之后每 3 秒执行一次 executor.scheduleAtFixedRate(() -> System.out.println("周期性执行"), 2, 3, TimeUnit.SECONDS);
      1. 创建一个可以执行延迟任务或定时任务的线程池。
      2. 指定核心线程数 `corePoolSize`。
      3. 使用 `DelayedWorkQueue` 作为阻塞队列。
      4. 适用于需要执行定时任务或延迟任务的场景。
   5. `Executors.newSingleThreadScheduledExecutor()`:
      - 创建一个单线程的可以执行延迟任务或定时任务的线程池。
      - 相当于 `newScheduledThreadPool(1)`。
      - 保证所有任务按照提交顺序依次执行。
      - 适用于需要顺序执行的定时任务或延迟任务。
5. 为什么线程池禁止使用 executors 创建
   1. 因为 fix，single 使用 linked 阻塞队列，会 OOM
   2. cache 和 `newScheduledThreadPool` 的最大线程数无上限
6. 和 Mq 相比的优缺点
   1. 阻塞队列可以看成 Mq 的消息堆积，线程池和 mq 都能达到异步化和削峰的效果，线程池是想要吞吐量尽量大的情况下，达到缓冲的效果。
7. 什么时候用线程池，什么时候用 Mq
   1. 线程池中的任务无法持久化，当需要保证任务不会丢失，以及需要大量堆积的时候选用 mq，当然也可以用线程池的本地消息表来达到同样的效果
   2. 线程池只能是单机的，mq 可以供多个实例一起使用

### 通信工具类

1. Semaphore

   1. 存储资源，通过 accquire 获取，release 释放
      1. 资源不足时获取，获取资源的线程会被阻塞并放入 Semaphore 内部实现的 AQS 的等待队列中
2. Exchange

   1. 当一个线程调用 exchange 方法后，会处于阻塞状态，只有当另一个线程也调用了 exchange 方法，它才会继续执行。看源码可以发现它是使用 park/unpark 来实现等待状态切换的，但是在使用 park/unpark 方法之前，使用了 [CAS](https://javabetter.cn/thread/cas.html) 检查，估计是为了提高性能。因为 Exchanger 支持泛型，所以我们可以传输任何的数据，比如 IO 流或者 IO 缓存。
3. CountDownLatch

   1. 一个实现了 AQS 的计数器，初始值被设置了就不能改变了，用 countDown 方法进行扣件
   2. 扣减到 0 了之后才会唤醒被 CountDownLatch  await 的线程
4. CyclicBarrirer

   1. 和 CountDownLatch 类似，但是减到 0 了之后，会重置 count，并且随机

## JVM

### 内存模型

1. 运行时内存区：

   1. 线程私有：
      1. 虚拟机栈
      2. 本地方法栈
      3. 程序计数器
   2. 线程共有：
      1. 元空间
      2. 堆
         1. 运行时常量池
2. 虚拟机栈：

   1. 每个线程有自己的虚拟机栈，这个线程中，每调用一个方法，就创建一个栈帧
      1. 栈帧：存储局部变量表、操作数栈、动态链接、方法出口等信息
3. 堆：

   1. 内部结构：
      1. 新生代
         1. Eden 区
         2. Survivor 区
            1. From 区
            2. To 区
      2. 老年代
   2. 额外包含：
      1. 字符串常量池
         1. 字符串常量池中的字符串对象会经历从新生代到老年代的生命周期，具体它当前位于哪个区域取决于它的“年龄”以及垃圾回收器的具体行为。它并不是固定在新生代或老年代的
4. 元空间：

   1. 存储类的结构信息（如字段、方法信息等）
      1. 静态变量也是存储在元空间的
         1. _  // 静态变量：存储在元空间 (类元数据的一部分)_
            _    // "Static String Value" 这个字符串对象本身在堆的字符串常量池中_
            public static String staticVar = "Static String Value";
   2. 类信息：包括类的结构信息、类的访问修饰符、父类与接口等信息
   3. 常量池：存储类和接口中的常量，包括字面值常量、符号引用，以及运行时常量池
   4. 静态变量：存储类的静态变量，这些变量在类初始化的时候被赋值
   5. 方法字节码：存储类的方法字节码，即编译后的代码
   6. 符号引用：存储类和方法的符号引用，是一种直接引用不同于直接引用的引用类型
   7. 运行时常量池：存储着在类文件中的常量池数据，在类加载后在方法区生成该运行时常量池
   8. 常量池缓存：用于提升类加载的效率，将常用的常量缓存起来方便使用。
5. 常量池：

   1. 类文件常量池 (Class File Constant Pool)
      - 数量：每个 `.class` 文件都有一个。当你编译一个 Java 源文件（`.java`）时，每个生成的类（`.class`）或接口文件内部都会包含一个常量池。
      - 位置：存储在 `.class` 文件的特定结构中。这是静态的，是编译时生成的。
   2. 运行时常量池 (Runtime Constant Pool)
      - 数量：每个被 JVM 加载的类或接口都有一个自己独立的运行时常量池。
      - 位置：
        - JDK 1.8 及以后：存储在 元空间 (Metaspace) 中。元空间使用的是本地内存（Native Memory）。
        - JDK 1.7：部分内容（如符号引用）仍在永久代，字符串常量池移至堆。
        - JDK 1.6 及以前：存储在 永久代 (Permanent Generation) 中，永久代是方法区的一种实现，位于 JVM 堆的一部分（逻辑上，物理实现可能不同）。
   3. 字符串常量池 (String Constant Pool / String Table)
      - 数量：在 JVM 中通常是全局唯一的，被所有线程共享。
      - 位置：
        - JDK 1.7 及以后：存储在 Java 堆 (Heap) 中。
        - JDK 1.6 及以前：存储在 永久代 (Permanent Generation) 中。
      - 注意：运行时常量池中存储的是字符串字面量的符号引用，或者解析后指向堆中字符串常量池里具体 `String` 对象的直接引用。

### 类初始化和类加载

1. 类加载

   1. 类的加载过程
      1. Javac 编译出字节码
      2. 加载：
         1. 读取 class 文件（二进制流），生产静态数据结构放到元空间中，并生产一个 Class 类的对象放到堆中
            1. 元空间（Metaspace）
               - 存储类的 元数据（Class 元信息），包括：
                 - 类名、父类、接口
                 - 字段（Field）信息（包括静态变量）
                 - 方法（Method）信息（包括静态方法）
                 - 常量池（Constant Pool）
               - 在初始化阶段：
                 - 静态变量的 值 是直接存储在方法区（JDK 1.8+ 是 Metaspace）的。这样访问静态变量时，JVM 可以直接通过类引用找到它们，而不需要先找到 `Class` 对象。
                 - 静态方法的 字节码 存储在方法区（元空间）。调用静态方法时，JVM 直接从方法区读取字节码，并在栈帧中执行
            2. 堆（Heap）
               - 会创建一个 `java.lang.Class` 对象，它是类的运行时表示（Runtime Representation）。
               - 这个 `Class` 对象是一个普通的 Java 对象，存储在堆中。
               - 它提供了反射（Reflection）能力，比如 `MyClass.class` 或 `obj.getClass()`
      3. 连接：
         1. 验证：
            1. 校验元数据等内容是否合规
         2. 准备：
            1. 为所有静态变量分配空间和赋 0 值
            2. 如果被 final 修饰，那么会被直接赋值
         3. 解析：
            1. 常量池中的符号引用替换为直接引用
               1. Java 类编译 A 的时候，不知道引用的 B 有没有被编译，不知道 B 的实际地址
               2. 运行时，会检查 B 是否加载，如果 B 没有被加载，那么会出发 B 的类加载，然后把对应的地址替换掉之前 A 的符号引用
                  1. 静态解析：如果 B 是一个实现类，那么直接替换
                  2. 动态解析：如果 B 是一个接口或者抽象类，那么解析阶段就会被替换到初始化之后，等到运行过程中发生调用时，会得到具体的类型信息，这时再替换符号引用
      4. 初始化：
         1. JVM 会执行类的类构造器 `<clinit>()` 方法。`<clinit>()` 方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块 (`static{}`) 中的语句合并产生的。编译器收集的顺序是由语句在源文件中出现的顺序决定的。
         2. 为 class 层面的成员变量和静态变量赋值
         3. 这里不是指调用构造函数，构造函数要用 new 来触发，时机：由 Java 虚拟机自动调用。通常发生在以下情况首次发生时：
            - 创建类的实例 (即 `new` 一个对象)。
            - 访问类的静态变量 (getstatic, putstatic)。
            - 调用类的静态方法 (invokestatic)。
            - 反射调用 (如 `Class.forName("...")`)。
            - 初始化一个类的子类时，会先初始化其父类。
            - 如果一个接口定义了 `default` 方法，其实现类在初始化时也会导致接口的初始化。
            - JVM 启动时指定的主类（包含 `main` 方法的类）。
   2. 为什么需要分为“准备阶段赋零值”和“初始化阶段赋具体值”这两个步骤
      1. 关注点分离：
         1. 准备阶段：只需要开辟空间和赋统一的默认值。这是一个基础的、确保变量有初始状态的步骤。非常快速。如果在准备阶段不赋零值，那么在 `<clinit>()` 方法中访问这些变量时，它们的状态就是未定义的，这会非常危险
         2. 初始化阶段：涉及到用户定义的逻辑（静态代码块、静态变量的显式赋值语句）。这些逻辑可能很复杂，可能依赖其他类，甚至可能抛出异常。将这部分放到 `<clinit>()` 方法中统一执行，使得虚拟机可以按部就班地执行类的初始化逻辑。
2. 类结构：

   1. 一个 Java 对象在内存中的布局通常可以分为三个部分（以 HotSpot 虚拟机为例）：
      1. 对象头（Object Header）
      2. 实例数据（Instance Data）
      3. 对齐填充（Padding） (可选)
   2. 我们重点来看对象头：
      1. 在 HotSpot 虚拟机中，对象头根据对象是否为数组而有所不同：
      2. 对于非数组对象：对象头通常占用 2 个机器字（Word）的大小。
         1. Mark Word (标记字) ：
            1. 大小：1 个机器字 (32 位 JVM 中是 4 字节，64 位 JVM 中是 8 字节)。
            2. 用途：存储对象自身的运行时数据，如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等。
            3. 动态性：Mark Word 的设计非常巧妙，它是一个非固定的数据结构，会根据对象所处的状态复用自己的存储空间。例如：
               1. 无锁状态：存储对象的 HashCode、GC 分代年龄、是否偏向锁（1 位）。
               2. 偏向锁状态：存储偏向线程 ID、Epoch、GC 分代年龄、是否偏向锁（1 位）。
               3. 轻量级锁状态：存储指向栈中锁记录（Lock Record）的指针。
               4. 重量级锁状态：存储指向互斥量（Monitor）的指针。
               5. GC 标记状态：仅仅是一些 GC 相关的标记。
         2. Klass Pointer (类型指针 / 类元数据指针) ：
            1. 大小：1 个机器字。
            2. 用途：指向方法区（或元空间）中该对象对应的类元数据（`Klass` 对象）。虚拟机通过这个指针来确定这个对象是哪个类的实例。通过这个指针，可以获取到类的所有信息，如方法、字段等。
            3. 指针压缩：在 64 位 JVM 中，如果堆内存小于特定大小（如 32GB，取决于具体配置和 JVM 版本），Klass Pointer 默认会开启指针压缩，使其只占用 4 字节，从而节省内存。
      3. 对于数组对象：
         对象头会比非数组对象多存储一个用于记录数组长度的数据。
         1. Mark Word：同上。
         2. Klass Pointer：同上。
         3. Array Length (数组长度) ：
            1. 大小：通常是 4 字节。
            2. 用途：存储数组的长度。这是 `array.length` 语句能快速返回数组长度的原因。
   3. 实例数据（Instance Data）:
      1. 这是对象真正存储有效信息的部分，也就是程序代码里所定义的各种非静态成员变量。
      2. 存储顺序会受到虚拟机分配策略参数和字段在 Java 源码中定义顺序的影响。
      3. HotSpot VM 的默认分配策略是：相同宽度的字段总是被分配到一起。在满足这个前提下，父类中定义的变量会出现在子类变量之前。如果 `CompactFields` 参数为 true（默认 true），子类中较窄的变量也可能会插入到父类变量的空隙中。
   4. 对齐填充（Padding）:
      1. 这不是必然存在的，也不是对象结构中必须的数据。
      2. 目的：HotSpot VM 的自动内存管理系统要求对象的大小必须是 8 字节的整数倍。对象头本身是 8 字节的倍数（1 个或 2 个机器字，在 64 位系统下，即使开启指针压缩，Klass Pointer 占 4 字节，Mark Word 占 8 字节，总共 12 字节，如果没数组长度，就会填充 4 字节凑够 16 字节。如果是数组，Mark Word 8 + Klass Pointer 4（压缩后） + Array Length 4 = 16 字节，天然对齐）。如果实例数据部分的长度加上对象头不是 8 字节的整数倍，就需要通过对齐填充来补足。这主要是为了优化 CPU 访问内存的效率。
3. 对象加载过程：

   1. 类加载检查
   2. 新生代中分配空间
   3. 空间赋 0 值（字段赋初始值）
   4. 设置对象头信息
   5. 执行 init 方法（构造方法）
4. 类加载器

   1. 每个加载器会有自己指定的类加载路径，双亲委派机制会让父加载器先在自己的路径中查找，查不到再往下，这样核心类永远是启动类加载器加载
   2. 加载器负责的类加载

### 垃圾回收

1. 判断垃圾的方法：

   1. 引用分析：
      1. 无法解决循环引用的问题
   2. 可达性分析：
      1. 从 GC Root 开始，无法到达的对象
      2. GC Root 包括：
         1. 栈帧中引用的对象
         2. 后台守护线程引用的对象
         3. 静态变量引用的对象
      3. 问题：STW 时间长
   3. 三色标记法：减少 STW 时长，CMS 和 G1 使用
      1. 三个阶段：
         1. 初始标记：STW，将根对象和根对象直接引用的对象标记为灰色
         2. 并发标记：不需要 STW，从灰色对象出发，将他们直接引用的对象标记为灰色，已经被遍历过的对象（两次）标记为黑色，并发，需要写屏障
            1. 三色标记写屏障：是 GC 算法的内部机制，当应用程序线程修改对象引用关系时（例如，一个已经被标记为“黑色”的对象，现在要指向一个尚未被访问过的“白色”对象），写屏障会介入。根据具体的 GC 实现（如 SATB - Snapshot-At-The-Beginning，或增量更新策略），写屏障可能会将新引用的白色对象标记为灰色，或者将修改引用的黑色对象重新标记为灰色，以确保 GC 线程能够正确地追踪到所有活动对象
         3. 重新标记：STW，从灰色对象开始，重新遍历对象图，将他们直接引用的对象标记为灰色，已经被遍历过的对象（两次）标记为黑色。
         4. 删除白色对象
      2. 问题：
         1. 多标：不用管，量小，下次会查到的
         2. 漏标：
            1. 发生条件：同时发生
               1. 有一个黑色对象在标记后指向了一个白色对象
               2. 所有的灰色对象在被标记之前都取消了对这个白色对象的引用
            2. 解决：
               1. CMS：增量更新
                  1. 把新指向了白色对象的黑色对象加入到扫描队列中
               2. G1：原始快照
                  1. 把扫描阶段灰色对象取消引用的白色对象加入扫描队列中
2. 垃圾回收的算法：

   1. 标记-清除
   2. 标记-整理
   3. 复制算法
   4. 分代回收
3. 垃圾回收器：

   1. 其他：
      1. 新生代：
         1. serial GC
            1. 标记-复制算法，需要 STW
      2. 老年代：
         1. serial old GC
            1. 标记-整理算法，需要 STW
   2. CMS
      1. 处理范围：老年代
      2. 采用标记-清除算法
      3. 当老年代的使用达到设置的阈值后，启动三色标级法处理
   3. G1（默认使用）
      1. 处理范围：新生代 + 老年代
      2. 逻辑：
         ![](static/YVqzbfF4BoXW8CxF6K2cslB9njf.png)
      3. 分代：
         1. G1 有专门的大对象区，可以不让大对象进入老年代
         2. 整体看起来是分类整理，局部是分类复制
         3. 对老年代使用分类整理
         4. **新生代收集 (Young GC / Minor GC） Eden 区满时触发**
            1. 对新生代使用复制算法（STW）
      4. 分区：
         1. 每个 region 属于不同的代，每个 region 上有一个 RememberSet，用来记录这个 region 中的对象指向的其他 region 中的对象，以免年轻代垃圾扫描的时候需要 STW 查找整个老年代
4. 不同的 GC

   1. FullGC：
      1. 不止堆，元空间他们也会一起 GC
5. 安全点：

   1. JVM 要等到安全点才能 STW，挂起所有线程
   2. 范围：
      1. 方法返回之前 (Method Return) ：
         - 当一个方法即将返回给调用者时，通常是一个比较自然的安全点。此时方法栈帧即将弹出，局部变量等状态相对清晰。
      2. 调用非 JNI 方法之前 (Call Sites) ：
         - 在即将调用另一个 Java 方法（非 JNI 调用）之前。
      3. 循环的末尾或回边 (Loop Back-edges) ：
         - 对于长时间运行的循环，在循环的跳转回循环开始处（回边）设置安全点是非常重要的。如果没有这个，一个包含死循环或者执行时间极长的循环的线程将永远无法到达安全点，从而阻塞 JVM 的全局操作。
         - 例如，在 `for`、`while`、`do-while` 循环的条件判断或迭代更新之后。
      4. 代码中的计数循环 (Counted Loops) ：
         - 对于那些可以被编译器识别为会执行多次迭代的循环（例如，`for (int i = 0; i < large_number; i++)`），编译器可能会在循环内部插入安全点检查，而不是仅仅在回边。
      5. 抛出异常的位置 (Exception Handling) ：
         - 在异常对象创建和准备抛出时，可以是一个安全点。
      6. 解释执行模式下的特定字节码指令之后：
         - 当 JVM 以解释模式执行字节码时，它可以在某些特定的字节码指令执行后插入安全点检查。
      7. JIT 编译代码中的特定位置：
         - JIT (Just-In-Time) 编译器在将字节码编译成本地机器码时，也会策略性地在生成代码中插入安全点检查指令。这些位置的选择会考虑到性能和安全点到达的及时性。

### 四种引用

1. 强引用:Java 中默认的引用类型,一个对象如果具有强引用那么只要这种引用还存在就不会被回收。比如 String
   str = new String("Hello ThreadLocal");,其中 str 就是一个强引用,当然,一旦强引用出了其作用域,那么强引
   用随着方法弹出线程栈,那么它所指向的对象将在合适的时机被 JVM 垃圾收集器回收。
2. 软引用:如果一个对象具有软引用,在 JVM 发生内存溢出之前(即内存充足够使用),是不会 GC 这个对象的;只
   有到 JVM 内存不足的时候才会调用垃圾回收期回收掉这个对象。软引用和一个引用队列联合使用,如果软引用所
   引用的对象被回收之后,该引用就会加入到与之关联的引用队列中。
3. 弱引用:这里讨论 ThreadLocalMap 中的 Entry 类的重点,如果一个对象只具有弱引用,那么这个对象就会被垃圾
   回收器回收掉(被弱引用所引用的对象只能生存到下一次 GC 之前,当发生 GC 时候,无论当前内存是否足够,弱
   引用所引用的对象都会被回收掉)。弱引用也是和一个引用队列联合使用,如果弱引用的对象被垃圾回收期回收
   掉,JVM 会将这个引用加入到与之关联的引用队列中。弱引用的对象可以通过弱引用的 get 方法得到,当引用的
   对象被回收掉之后,再调用 get 方法就会返回 null。
4. 虚引用:虚引用是所有引用中最弱的一种引用,其存在就是为了将关联虚引用的对象在被 GC 掉之后收到一个通
   知。

## Spring

### IOC & DI & AOP

1. Ioc：

   1. Ioc 是一种设计思想，不是具体的实现方式，IOC 通过把依赖对象的查找和创建交给一个外部容器，来达到松耦合，资源集中管理的目的
      1. 松耦合：只需要标注需要注入哪个类，不需要关心类的具体实现和创建，类的修改，包括构造函数的修改，都不用再去改依赖了这个类的类
2. DI：

   1. DI 是 Ioc 的一种具体实现方式，通过依赖注入的方式，来代替原来主动 new 一个对象
   2. Spring 中 DI 的方式：
      1. 常见三种 @ Autowire 实现的
         1. setter 注入：
            1. 优点：
               1. 可选依赖 (Optional Dependencies) :
                  - 这是 Setter 注入最主要和最合理的用途。如果一个依赖不是 Bean 正确运行所必需的，或者它有一个合理的默认值，那么 Setter 注入就很合适。你可以不调用 setter 方法，这样 Bean 就会使用默认值或者该依赖为 null。
                  - 相比之下，构造器注入通常用于注入必需的依赖。如果一个依赖是必需的，那么对象在构造完成时就应该拥有它，否则对象可能处于不完整或无效状态。
               2. 灵活性和可重配置性 (Flexibility and Reconfigurability) :
                  - Setter 方法允许你在 Bean 实例化之后，甚至在运行时（尽管不常见，例如通过 JMX）更改依赖。这意味着你可以重新配置一个已经存在的 Bean 实例的依赖。
                  - 构造器注入一旦完成，依赖通常是固定的（特别是如果字段被声明为 `final`）。
               3. 可以解决循环依赖问题
            2. 缺点：
               1. 对象在调用 setter 方法之前可能处于不完整状态。
               2. 不能保证所有必需的依赖都被注入（除非手动检查或使用 `@Required` 等注解，但这又增加了复杂性）。
               3. 依赖关系不如构造器注入那样明确。
               4. 不利于创建不可变对象 (immutable objects)。
         2. 构造函数注入：（官方推荐）
            1. 问题：
               1. 无法解决循环依赖问题，因为实例化 Bean 的阶段，就要求 Bean 全部加载好，无法通过三级缓存的机制加载成功
            2. 优点：
               1. 这样可以保证在加载 Bean 的实例化阶段，需要依赖的 Bean 就要已经创建完成，不存在循环依赖（循环依赖本来就不好）
               2. 避免 NullPointerException，因为如果字段不存在，那么会创建失败直接报错
               3. 方便测试：不需要使用反射或者其他方式，只需要看构造函数，然后传入相应的测试类即可
         3. 字段注入：
            1. 问题：
               1. 不利于测试
                  1. 隐藏的依赖关系：类的依赖不是通过其公共构造函数声明的，使得不看内部实现就难以知道它依赖什么。
                  2. 难以在没有 DI 框架的情况下实例化和注入：在纯单元测试中，对象创建后，依赖字段是 `null`。你需要额外的步骤（setter 或反射）来注入模拟对象。
                  3. 对象可能处于无效状态：如果忘记注入依赖（例如，在测试中），对象的方法可能会因为 `NullPointerException` 而失败。
                  4. 测试代码更复杂或侵入性更强：要么需要为测试添加 setter，要么使用反射，或者依赖测试框架的特定功能
               2. 破坏封装性：私有的属性会被容器通过反射来设置
      2. XML 注入
      3. @ Resource 和 @Injection
         1.
      4. 构造器自动注入
         1. 只有一个构造方法时，可以自动调用构造器注入
   3. @ Resource  与 @ Autowire 的区别
      1. 查找顺序不同，提供者不同
         1. @Resource 由 JDK 提供，所有的 IOC 容器都会支持它
            1. 他的查找，是先 byName，再 byType
         2. @ Autowire 是 Spring 提供
            1. 他的查找，是先 byType，再 byName
      2. 作用域不同：
         1. Autowire  可在字段、setter、构造器方法上
         2. Resource 可在字段、setter 方法上
      3. 默认要求不同：
         1. Autowire 要求 Bean 存在，否则报错
         2. Resource 无所谓，找不到就给 null
3. AOP：

   1. 概念：抽离出公共的逻辑进行代码复用，开发者可以专注于业务开发
   2. AOP 的概念点：
      1. Aspect 切面：即某个类
         1. Pointcut 切入点
            1. 在切面那，通过注解来定义这个切面在哪些包，哪些类中生效
         2. Advice 通知
            1. 具体要执行的操作
            2. 五种：
               1. Before
               2. After return
               3. After thoring
               4. After finally
               5. Around
                  1. 在方法调用前后都行，通过 `result = joinPoint.proceed(); `_// 使用原始参数执行 __ 来确定前后_
      2. target 目标对象：即被切入点指定，将被代理的对象
      3. JoinPoint 连接点：运行时某一时刻正在执行的 AOP 方法
      4. Waving 织入：即代理过程
   3. AOP 的实现：
      1. 通过动态代理在 Bean 加载流程的 BeanPostProcessor 后置处理中进行
   4. 什么情况下 AOP 会失效：
      1. AOP 是通过动态代理实现的，动态代理实效，AOP 就失效
         1. 当方法被 final 修饰时，无法被重写，所以会失效
         2. 方法是私有的时候，也会失效
         3. 方法静态时，也无法被代理，因为是直接调用的类的
         4. 代理类内部的调用

### Bean

1. Bean 的作用域有哪些：

   1. **singleton** : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。
   2. **prototype** : 每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。
      1. Spring 容器负责创建 `prototype` Bean 的实例，并进行依赖注入等初始化工作。但是，一旦创建完毕并将实例返回给调用者后，Spring 不再管理该实例的完整生命周期。这意味着销毁回调方法（如 `@PreDestroy` 或 `DisposableBean` 接口）将不会被自动调用。你需要手动管理这些实例的销毁
   3. **request** （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。
   4. **session** （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。
   5. **application/global-session** （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。
   6. **websocket** （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。
2. 为什么 Spring 要设计成单例模式

   1. 因为 Spring 鼓励无状态设计，从而避免为每一个线程创建和销毁 bean 带来的开销，同时 AOP 也依赖于单例的 Bean，会使代理更简单
3. Bean 是否是线程安全的：

   1. 单例的 Bean，如果是无状态的，那么就是线程安全的
   2. 多例的 Bean，每次获取会获得一个新的 Bean，不会和其他线程共享，也是线程安全的
4. Bean 的加载流程

   1. 实例化：
      1. 容器中查找 Bean 不存在 bean 实例（单例情况下），就先实例化 bean，也就是调用构造函数（如果有工厂方法则调用工厂方法）使用 doCreateBean 方法
   2. 初始化：
      1. 设置属性值：处理 @ autowired 或者是 set 方法注入的属性
         1. 在这个方法中，三层缓存解决循环依赖问题
            1. 循环依赖问题：在初始化过程中，相互依赖
               1. 三层缓存：
                  1. 一级缓存：存储完整的创建好的单例 Bean
                  2. 二级缓存：存储的是实例化了但没有初始化的 bean 对象（半成品对象）
                  3. 三级缓存：单例 bean 的创建工厂
               2. 解决过程：A 依赖 B，在初始化 A 的过程中，会创建出完整的 B，再注入 A，获得完整的 A
                  ![](static/GlOCbn6I7oo3NMxsTVNcwFiWnXg.png)
                  - 假设 `ServiceA` 依赖 `ServiceB`，`ServiceB` 依赖 `ServiceA`：
                    1. `getBean("serviceA")` 开始：
                       - 检查一级缓存 `singletonObjects`：没有 `serviceA`。
                       - 检查二级缓存 `earlySingletonObjects`：没有 `serviceA`。
                       - 检查三级缓存 `singletonFactories`：没有 `serviceA`。
                       - 标记 `serviceA` 正在创建中（放入 `singletonsCurrentlyInCreation` 集合）。
                    2. 创建 `serviceA` 实例：
                       - 实例化 `serviceA` ：通过反射调用构造函数创建 `serviceA` 的原始对象（此时 `serviceB` 属性为 `null`）。
                       - 重点来了：如果允许循环依赖（默认单例是允许的），Spring 会为 `serviceA` 创建一个 `ObjectFactory`。这个工厂的作用是，当其他 Bean 需要 `serviceA` 时，它可以返回一个 `serviceA` 的早期引用。这个工厂被放入三级缓存 `singletonFactories` 中：`singletonFactories.put("serviceA", () -> getEarlyBeanReference("serviceA", mbd, bean))`。`getEarlyBeanReference` 方法很重要，它会检查是否有 `BeanPostProcessor`（如 AOP 的 `AnnotationAwareAspectJAutoProxyCreator`）需要提前为 `serviceA` 创建代理。如果需要，工厂返回的就是代理对象；如果不需要，返回的就是原始对象。
                    3. 填充 `serviceA` 的属性：
                       - Spring 发现 `serviceA` 依赖 `serviceB`（通过 `@Autowired` 或 setter）。
                       - Spring 调用 `getBean("serviceB")` 来获取 `serviceB`。
                    4. `getBean("serviceB")` 开始：
                       - 检查一级缓存 `singletonObjects`：没有 `serviceB`。
                       - 检查二级缓存 `earlySingletonObjects`：没有 `serviceB`。
                       - 检查三级缓存 `singletonFactories`：没有 `serviceB`。
                       - 标记 `serviceB` 正在创建中。
                    5. 创建 `serviceB` 实例：
                       - 实例化 `serviceB`：创建 `serviceB` 的原始对象。
                       - 将 `serviceB` 的 `ObjectFactory` 放入三级缓存 `singletonFactories`。
                    6. 填充 `serviceB` 的属性：
                       - Spring 发现 `serviceB` 依赖 `serviceA`。
                       - Spring 调用 `getBean("serviceA")` 来获取 `serviceA`。
                    7. `getBean("serviceA")` 再次被调用 (这次是为了注入 `serviceB`)：
                       - 检查一级缓存 `singletonObjects`：没有 `serviceA`（因为它还没完全初始化）。
                       - 检查二级缓存 `earlySingletonObjects`：没有 `serviceA`（因为工厂还没被调用）。
                       - 检查三级缓存 `singletonFactories`：找到了 `serviceA` 对应的 `ObjectFactory`！
                       - 调用 `serviceA` 的 `ObjectFactory` ：
                         - 工厂执行 `getEarlyBeanReference()`。这个方法会检查是否需要为 `serviceA` 创建代理。
                         - 假设 `serviceA` 需要 AOP 代理，则此时会创建 `serviceA` 的代理对象 `proxyA`。
                         - 工厂返回 `proxyA` (或原始 `serviceA` 如果无代理)。
                       - 将工厂返回的 `proxyA` (或原始 `serviceA`) 放入二级缓存 `earlySingletonObjects`。
                       - 从三级缓存 `singletonFactories` 中移除 `serviceA` 的工厂 (因为已经用掉了，且产物已放入二级缓存)。
                       - 返回 `proxyA` (或原始 `serviceA`) 给 `serviceB`。
                    8. `serviceB` 完成属性填充：
                       - `serviceB` 的 `serviceA` 属性被成功注入了 `proxyA` (或原始 `serviceA`)。
                       - `serviceB` 继续执行其初始化过程（`Aware` 接口, `BeanPostProcessor` 等）。
                       - `serviceB` 完全初始化完成。
                       - 将完全初始化的 `serviceB` (可能是原始 `serviceB` 也可能是 `proxyB`) 放入一级缓存 `singletonObjects`。
                       - 从二级缓存 `earlySingletonObjects` 中移除 `serviceB` (如果之前放进去过)。
                       - 从 `singletonsCurrentlyInCreation` 中移除 `serviceB`。
                       - `getBean("serviceB")` 调用结束，返回完全初始化的 `serviceB`。
                    9. `serviceA` 继续属性填充：
                       - `serviceA` 的 `serviceB` 属性被成功注入了完全初始化的 `serviceB` (或 `proxyB`)。
                       - `serviceA` 继续执行其初始化过程（注意：它的早期引用 `proxyA` 已经被 `serviceB` 持有了）。
                       - `serviceA` 完全初始化完成。
                       - 将 `serviceA` 的最终形态 (可能是 `proxyA`，也可能是原始 `serviceA` 如果没有被代理且早期暴露的就是它) 放入一级缓存 `singletonObjects`。 这里有个细节，如果早期暴露的是代理，那么放入一级缓存的也是这个代理；如果早期暴露的是原始对象，但后续某个 `BeanPostProcessor` (如 AOP) 将其包装成了代理，那么最终放入一级缓存的是代理对象。
                       - 从二级缓存 `earlySingletonObjects` 中移除相关条目 (如果最终放入一级缓存的对象和二级缓存中的是同一个引用，则二级缓存中的会被覆盖或保持)。
                       - 从三级缓存的工厂中获取的那个对象，如果它就是最终放入一级缓存的对象，那二级缓存 `earlySingletonObjects.remove("serviceA")` 就移除了它（因为要放到一级缓存）。
                       - 从 `singletonsCurrentlyInCreation` 中移除 `serviceA`。
                       - `getBean("serviceA")` 调用结束，返回完全初始化的 `serviceA` (或 `proxyA`)。
               3. 为什么二级缓存也可以，但是还是加上三级缓存缓存工厂？这个问题是核心。
                  - 如果只有二级缓存（`earlySingletonObjects`）：
                    1. 创建 A，实例化 A。
                    2. 此时，如果 A 需要被代理，什么时候创建代理？
                       - 方案 1：立即创建代理并放入二级缓存。 这样的话，即使 A 没有发生循环依赖，或者注入 A 的对象不需要 A 的代理形态，A 的代理也会被过早创建。这可能不是我们期望的，因为代理的创建也有成本，并且我们希望代理的创建是在真正需要的时候（比如被 `BeanPostProcessor` 包装时）。
                       - 方案 2：将原始 A 放入二级缓存。 当 B 依赖 A 时，B 获取到的是原始 A。如果 A 后来在自身的初始化过程中（比如某个 `BeanPostProcessor`）被增强生成了代理 A'，那么 B 持有的还是原始 A，而其他地方获取到的 A 可能是代理 A'。这就导致了 Bean 引用的不一致性。AOP 等功能就会失效。
                  - 三级缓存 (`singletonFactories`) 的优雅之处：
                    1. 创建 A，实例化 A。
                    2. 将一个能产生 A (可能是原始 A，也可能是代理 A) 的工厂 (`ObjectFactory`) 放入三级缓存。
                    3. 这个工厂本身并不立即执行，它只是一个“承诺”——“如果你需要 A 的早期引用，就来调用我，我会给你正确的那个（可能是代理的）”。
                    4. 只有当真正发生循环依赖，比如 B 需要提前获取 A 时，才会去调用三级缓存中的工厂。
                    5. 工厂被调用时，它会咨询所有相关的 `SmartInstantiationAwareBeanPostProcessor`（比如 AOP 的处理器），询问它们是否需要提前暴露一个特殊的（比如代理的）Bean 引用。
                    6. `getEarlyBeanReference()` 方法就是这个咨询点。如果 A 需要被代理，那么 AOP 处理器就会在这里返回 A 的代理。如果不需要，就返回原始 A。
                    7. 工厂的产物（原始 A 或代理 A）随后被放入二级缓存 `earlySingletonObjects`，供后续可能的其他循环依赖者使用（确保它们拿到的是同一个早期引用），并且工厂从三级缓存中移除。
      2. 监测 Aware 方法，执行有相关接口的方法
         1. Aware 方法可以提供 Bean 容器的信息给 Bean，也可以获取到其他 Bean
         2. 例如获得配置文件的 ID
      3. BeanPostProcessor 前置处理
         1. 一些自定义注解的解析和处理是在这里进行
      4. `@PostConstruct` 运行
         - `@PostConstruct` 是 bean 内部 的初始化逻辑，定义在 bean 自己的类中，用于 bean 自配置。
         - `BeanPostProcessor` 是 外部 于 bean 的处理器，它是一个更通用的机制，可以影响多个 bean 的初始化过程，通常用于框架级别的扩展或横切关注点的实现。
      5. InitializingBean 接口
         1. 调用 afterPropertiesSet 方法，在所有属性值被设定完成之后进行初始化操作
         2. 这个方法可以返回原始的 Bean 实例，也可以返回一个包装过的 Bean 实例（例如，一个代理对象）
         3. SecurityFilterChain 的配置在这里进行
         4. 自定义的 init-method 方法
      6. BeanPostProcessor 后置处理
         1. AOP 代理在这里执行
         2. 定时任务在这里执行
   3. 注册 Destruction 回调函数
   4. 开始使用

### Spring 事务

1. Spring 中的事务支持：

   1. 编程式事务：通过硬编码开启和提交、结束事务
   2. 声明式事务：用注解实现，通过 AOP 来开启事务
      1. 缺点：
         1. 最小粒度为方法，没办法对代码块使用
         2. 容易被开发者忘记，导致在方法中加入 RPC 调用，消息发送，缓存更新等无法通过事务回滚的操作
         3. 声明式事务容易失效
2. 事务的传播级别：

   1. required ：有事务则加入事务，没有事务则创建一个事务
   2. supports：有事务则加入事务，没有事务则正常运行
   3. mandatory：有事务则加入事务，没有事务则报错
   4. nested：有事务创建子事务，外部事务回滚导致子事务回滚，子事务回滚不影响外部事务。没有事务则正常进行
   5. requires_new：有事务将原事务挂起，创建新的事务。新事务与外部事务是独立的，各自提交或回滚
   6. not_support：有事务将原事务挂起，然后正常运行
   7. never：有事务就报错，一直按照无事务运行
3. 事务的回滚：

   1. 通过 rollbackFor 属性设置，默认是 runtimeException 或者 error 才回滚。可以指定某个错误和异常以及他的子类来回滚
4. 事务在哪些情况下会失效：

   1. AOP 失效
   2. 事务没用对：
      1. 传播属性没设置对
      2. rollbackFor 设置的级别不对
      3. 异常被捕获，事务不会触发
   3. 多线程情况下：
      1. 声明式事务通过 ThreadLocal 来存储上下文，无法使用事务的原子性
5. 如何实现多线程事务：

   1.
6. 事务的隔离级别：

   1. 和 mysql 一致，Spring 只是将隔离级别的设置传递给底层的 JDBC 驱动和数据库

### MVC

1. 为什么 Service 要拆成接口和实现类：

   1. 方便更换实现类不改其他代码
   2. AOP 编程支持
2. MVC 的核心组件：

   - **DispatcherServlet**：**核心的中央处理器**，负责接收请求、分发，并给予客户端响应。
   - **HandlerMapping**：**处理器映射器**，根据 URL 去匹配查找能处理的 `Handler` ，并会将请求涉及到的拦截器和 `Handler` 一起封装。
   - **HandlerAdapter**：**处理器适配器**，根据 `HandlerMapping` 找到的 `Handler` ，适配执行对应的 `Handler`；
   - **Handler**：**请求处理器**，处理实际请求的处理器。
   - **ViewResolver**：**视图解析器**，根据 `Handler` 返回的逻辑视图 / 视图，解析并渲染真正的视图，并传递给 `DispatcherServlet` 响应客户端
3. MVC 的处理流程：
   ![](static/QrowbIXCCoMFh5xGaqOc5kLgnMe.png)

   1. 前后端分离的情况下：
      1. 请求从 VUE 的 axios 发送到 Spring 内置的 tomcat 服务器，由 dispatcherServlet 接受
      2. dispatcherServlet 会开始找匹配的 HandlerMapping，即扫描注解有 @RestController 的类，找其中匹配的 @RequestMapping（postMapping）
         1. 找到了之后，HandlerMapping 就会把 Handler（controller 方法）和连接器之类的包装成执行链返回给 dispatcherServlet
      3. `DispatcherServlet` 在通过 `HandlerMapping` 找到合适的 Handler (比如 `UserController` 的 `getUserById` 方法) 后，会选择一个能够处理这种 Handler 的 `HandlerAdapter` (通常是 `RequestMappingHandlerAdapter`)
         1. Adapter 会先解析参数，也就是把 @RequestBody 这些解析并绑定上去，然后用反射调用这个 handler 方法
         2. handler（controller）会进行下一步 service 之类的调用
         3. 调用结束之后，返回 返回值，（Controller 是 `@RestController` 或者方法上有 `@ResponseBody`，那么 `RequestResponseBodyMethodProcessor` (它也处理返回值) 会将返回的对象（如 `UserDTO`）序列化为 JSON (或其他协商的内容类型) 并写入 HTTP 响应体。）
      4. 前后端分离的情况下，就不需要视图渲染了，直接返回给前端

### Springboot

1. springboot 在 spring 的基础上增加了什么

   1. 自动配置
   2. 内嵌 web 服务器
   3. 约定大于配置
2. Springboot 启动流程：
   ![](static/C1PxbTFhGo8jF1xZ83accRoFnbc.png)

   1. 先是 new 一个 SpringApplication
      1. 这一步里完成了自动配置，加载监听类
   2. 然后调用 SpringApplication.run
      1. 创建 ConfigurableEnvironment 对象，加载各种环境变量和配置，如 application.yml 文件
      2. 打印 Banner
      3. 创建 ApplicationContext （Ioc 容器）
      4. 加载单例 Bean
      5. 开启 Tomcat
3. SpringBoot 的自动配置是什么：

   1. 前提：
      1. Spring 定义了一个接口，需要外部 jar 包来实现，从而快速引入第三方依赖：
         1. SpringBoot 在启动时会扫描外部引用 jar 包中的 `META-INF/spring.factories` 文件，将文件中配置的类型信息加载到 Spring 容器（此处涉及到 JVM 类加载机制与 Spring 的容器知识），并执行类中定义的各种操作。对于外部 jar 来说，只需要按照 SpringBoot 定义的标准，就能将自己的功能装置进 SpringBoot
      2. pom.xml 文件是 Maven 项目的对象模型文件，用于管理项目的依赖。当你向 pom.xml 添加一个 Spring Boot Starter（例如 spring-boot-starter-data-jpa），Maven 会下载这个 starter 包及其传递依赖的 JAR 文件。
         1. 关键在于 META-INF/spring.factories ：在这些下载的 JAR 包中（特别是 spring-boot-autoconfigure.jar 以及其他 spring-boot-starter-*.jar 对应的实现包），会有一个特殊的文件：META-INF/spring.factories。这个文件里用键值对的形式列出了各种可扩展的接口和它们的实现类。其中一个重要的键是 org.springframework.boot.autoconfigure.EnableAutoConfiguration，它的值就是一系列自动配置类的全限定名，用逗号分隔。
         2. 自动配置类（如上所述，通过 `spring.factories` 加载）本身也是 `@Configuration` 类。它们内部定义了很多 `@Bean` 方法。
         3. 当 Spring Boot 加载这些自动配置类时，如果它们的 `@ConditionalOn...` 条件满足，那么这些 `@Bean` 方法就会被执行，相应的 Bean 就会被创建并注册到 Spring 的 IoC 容器中。
   2. 流程：
      1. 启动主类时，其上的 @SpringBootApplication 注解内部的 @EnableAutoConfiguration 注解启动，@EnableAutoConfiguration 会调用 AutoConfigurationImportSelector 类，这个类中会调用方法获得所有的 pom.xml 里的引入 Jar 包的 META-INF/spring.factories，这个 factories 文件里就是
4. SpringBoot 的约定大于配置是什么：

   1. 自动配置（Auto-Configuration） ：这是核心。Spring Boot 会根据你项目 classpath 中的 jar 包（依赖）来智能地判断你需要哪些功能，并自动配置它们。
   2. 起步依赖（Starters） ：像 `spring-boot-starter-web` 或 `spring-boot-starter-data-jpa` 这样的起步依赖，它们将一组相关的常用依赖打包在一起，并触发相应的自动配置。
   3. 默认的项目结构和配置文件：例如，它期望 Java 代码在 `src/main/java`，资源文件在 `src/main/resources`，并且会自动加载 `application.properties` 或 `application.yml`
5. SpringBoot 过滤器和拦截器

   1. 过滤器 Filter：是 servlet 规范的，在进入 servelet 之前和之后执行
   2. 拦截器 interceptor：是 AOP 实现的，自己实现 preHandler 等方法后，通过 WebMvcConfigurer 类 addInterceptors 方法来配置
   3. 选择：
      1. 果你需要拦截所有进入应用程序的请求，包括静态资源（例如 CSS、JS、图片）的请求，以及非 Spring MVC 处理的请求（例如直接访问 Servlet），那么过滤器是唯一的选择。因为拦截器只拦截 DispatcherServlet 处理的请求
      2. 拦截器是 Spring MVC 框架的一部分，可以直接访问 Spring 容器中的 Bean，例如 Service、Repository 等。 这使得拦截器可以更容易地实现业务逻辑。 过滤器需要通过 `WebApplicationContextUtils` 等方式手动获取 Spring 上下文，相对麻烦一些。

## Mybatis

## Mysql

![](static/DGzBbeGecoIibEx6FwPceXm8nec.png)

### 索引

1. 什么是最左匹配原则
   1. 联合索引的情况下，优先按照最左边的列来作为索引建立二级索引。其他的列属于全局无序，局部有序
2. 索引下推和覆盖索引的区别
   1. 索引下推指的是可以在二级索引中先筛选一次再回表，而覆盖索引则是指二级索引中包含全部需要查找的信息，完全不需要回表
3. 为什么用 b+ 树，为什么不红黑树，为什么不跳表。
   1. 关系型数据库的主要任务是快速的查找和储存，频繁的修改和删除。mysql 的数据存储在磁盘上，为了快速查找，需要减少磁盘 IO 次数，也就是减少树的层数。红黑树每个节点只有两个子节点，层数太高。而 B 树的具体记录散布在各个节点中，难以满足 range 的需求。使用 B+ 树不仅可以减少 IO 而且非叶子节点只存储索引信息，在一次块读取中可以获得更多的索引信息
   2. 跳表也存在层数过高以及范围查找性能弱的情况
4. 索引失效的情况
   1. 在查询条件里对索引使用了函数或者表达式计算
   2. Or 条件之前的是索引列，Or 之后的不是索引列
      1. `OR` 条件的运作方式是，数据库需要评估每个条件，只要其中一个条件为真，整行数据就会被包含在结果集中。如果 `OR` 前面的条件可以使用索引，但 `OR` 后面的条件无法使用索引（比如不是索引列），数据库通常会放弃使用前面的索引，转而进行全表扫描。 这是因为数据库为了满足 OR 语句，必须扫描整个表，检查每一行记录是否满足至少一个条件。如果 `OR` 后面的列没有索引，那么数据库就无法利用索引来加速这个过程。
   3. 不满足最左匹配原则

### 锁

![](static/ArEibUFq9odvAexGQtRc2EDhnrf.png)

1. Mysql 有哪些锁
   1. 如下：
      ![](static/Th7Db9VH4oMsLvx10tWc7mw8n3c.png)
   2. 表级锁：
      1. 表锁：
         1. 上读锁之后，本线程不能读取别的表
      2. 元数据锁：
         1. 事务开启时默认获取元数据锁，防止其他线程修改表结构
         2. 事务都需要先获得元数据锁，如果有一个长事务导致 MDL 被长时间占用，如果这时来了一个修改表结构的 select，那么他会尝试获取 MDL 并加写锁，这种情况下由于写锁优先级高于读锁，会导致后续的 select 都被阻塞
      3. 意向锁：
         1. 用于加表锁之前，快速判断表中是否存在独占锁，防止需要遍历来判断
         2. 加记录的共享锁、独占锁之前，会先加上意向共享锁和意向独占锁。意向锁只与表锁冲突
      4. Auto-Inc 锁：
         1. 最开始是执行完插入语句之后释放，效果是为 AUTO_INCREAMENT 修饰的内容赋递增值
         2. 为了优化批量插入下的阻塞插入语句问题，提供了新的轻量级锁选项，将锁的释放时间提前到了赋值之后。
            1. 但是这样会导致主从不一致的问题
            2. TODO 为什么会导致主从不一致
   3. 行级锁：
      1. 插入意向锁：
         1. 在想插入的行被其他事务加了间隙锁的情况下，会插入一个插入意向锁，之后设置锁为等待状态并阻塞线程等待间隙锁释放
   4. 加行级锁的规则：都是从临键锁开始加
      1. 唯一索引：
         1. 等值查询：
            1. 记录存在：退化为记录锁
            2. 记录不存在：退化为间隙锁
         2. 范围查询：
            1. > =：
               >

               1. 等值记录存在：该条记录退化为记录锁
               2. 等值记录不存在：不退化，还是临键锁
            2. <= & < ：
               1. 条件值记录不存在：都退化为间隙锁
               2. 条件值记录存在：
                  1. <: 退化为间隙锁
                  2. <=: 不退化
      2. 非唯一索引
         1. 等值查询
         2. 范围查询
      3. 无索引
2. 关系型数据库的 ACID 特性是什么？在这个点赞场景下，如何体现？
3. 数据库事务的隔离级别有哪些？（读未提交、读已提交、可重复读、串行化）默认是哪个？在这个场景下选择哪个级别比较合适？为什么？
4. 这里应该选择什么锁来防止并发问题？这样会造成长时间阻塞吗
5. Insert 语句是如何加行级锁的
   1. 正常执行时不会加锁，靠聚簇索引自带的 trx_id 隐藏列作为隐式锁来保护记录
   2. 有间隙锁或者唯一键冲突时会不能插入记录
      1. 间隙锁，使用插入意向锁
      2. 唯一冲突，InnoDB 会在导致冲突的现有唯一索引记录上设置一个共享的 next-key lock (S-lock)。
         1. 当事务 A 因唯一键冲突而回滚其 `INSERT` 时，事务 B 可能已经删除了这条导致冲突的记录。如果事务 A 随后又尝试基于之前的判断（比如认为记录不存在）进行操作，就可能导致数据不一致。这个共享锁可以防止其他事务在该记录上进行写操作（如 `DELETE` 或 `UPDATE` 键值），直到持有锁的事务（即尝试插入的事务）结束。
            1. 防止尝试插入的事务是铁头娃，失败之后再次插入，假如没有这个锁，因为插入不加锁，那么可能其他事务已经删除了这条记录，第二次插入就会成功，导致数据库数据不一致
6. Next-key 锁
   1. update 语句在 where 条件里没有索引时，或者优化器选择了全表扫描，会导致给全表加锁

### 死锁

1. 为什么会产生死锁

   1. 当多条事务同时先 selcet for update 某个记录 A 和 记录 A +1 时，假如这个 A 不存在，那么这两个事务都会获得 A-1 到正无穷的临键锁，两个事务再执行 insert 时，就会导致双方都在等待对方释放临键锁或者间隙锁。造成死锁
2. 如何避免死锁：

   1. 设置事务等待锁的超时时间
   2. 开启主动死锁检测，监测到死锁的话会回滚死锁链条中的某一个事务

### 事务

### 日志

1. undolog

   1. 触发时机：执行增删改之前，将原始记录写入 undolog
   2. 刷盘时机：
      1. 和数据页一样，通过 buffer pool 刷盘
      2. 更改会被记录到 redolog 中
2. redolog

   1. 触发时机：事务执行时，记录对某个数据页做了某某修改
   2. 刷盘时机：
      1. 事务提交之前，先把 redolog 刷盘
      2. mysql 关闭时
      3. redolog 的 buffer 消耗一半时
      4. 后台线程每一秒都更新
   3. 当脏页写回磁盘之后，就会擦出对应的 redolog 内容
3. binlog

   1. 是 serve 层实现的，不是 innoDB 实现的
   2. 在默认模式下，记录下全部的 SQL 语句，可以全量恢复数据，而不是像 redolog 一样刷盘后擦出过期数据
   3. 刷盘时机：
      1. 事务提交时
4. 两阶段提交

   1. 两阶段提交和本地事务表的思路很像，通过在 redolog 中增加状态，通过查找 prepare 的 redolog 是否在 binlog 中有对应的记录存在，来保证分布式事务的一致性

### InnoDB

1. 内存中如何读取数据，数据页内部结构是什么
   1. 按照最小 16K 的数据页来进行读取的，File Header 记录前后数据页，形成双向链表
   2. 数据页内部的行之间按照主键从小到大组成单向链表
      1. 为了加快查询速度，使用目录页的方式，将数据页分为不同的槽，目录页存储每组最后一条记录的偏移量，同时每组最后一条记录，也是每组的最大记录中，会记录该组一共有多少条信息。然后从槽的开头进行遍历查找
   3. 槽的划分：除了虚拟最大和虚拟最小外，用户记录先是都在一个槽里，当数据超过限制，在原本的槽中插入一个新槽，如果删除记录，可能会导致某些槽覆盖的记录过少，这时相邻的槽可能会被合并（即删除一个槽）。

## Redis

![](static/Or4Ab7NP2ogKIdxpTiGcMWPznab.png)

### 数据结构

1. Redis 的常用数据结构有哪些？在这个场景下（json+ 删除），你会选择哪种？为什么？

   1. String
      1. 底层实现：
         1. SDS
            1. struct sdshdr {
               unsigned int len; // buf 中已占用的字节长度 (字符串实际长度)
               unsigned int alloc; // buf 中总共已分配的字节长度 (不包括头部和末尾的\0)
               // 在 Redis 3.2 之前，这里是 free 字段，表示 buf 中未使用的字节长度
               // 现在 alloc 表示总分配空间，free 可以通过 alloc - len 计算得到
               unsigned char flags; // 标志位，低 3 位表示类型 (sdshdr5, sdshdr8...)，高 5 位未使用
               char buf[]; // 实际存储字符串内容的柔性数组 (flexible array member)
               };
         2. Redis 根据存储内容的不同来调整 redisObject 上的编码
   2. Hash
      1. 底层实现：
         1. 如果哈希类型元素个数小于 `512` 个，所有值小于 64 字节，用 ListPack
         2. 否则用 hash 表
      2. 扩容：
         1. 先创建 2 倍的 hash 表，再等待每次调用原 hash 的时候，将这个槽里的 rehash 到新的表中
   3. List
      1. 底层实现：quickList
         1. 一个 quicklist 就是一个由多个 ziplist 组成的双向链表。也就是说，quicklist 中的每个节点 (我们称之为 quicklistNode) 并不直接存储数据元素，而是存储一个 ziplist。这个 ziplist 内部包含了多个实际的数据项。
   4. Set
      1. 底层实现：
         1. 集合中的元素都是整数且元素个数小于 `512`，使用整数集合
            - `intset` 本质上是一个有序的、不重复的整数数组。它可以存储 `int16_t`、`int32_t` 或 `int64_t` 类型的整数。`intset` 会根据存入的整数的大小自动选择最节省空间的整数类型。例如，如果开始存入的都是 `int16_t` 范围内的数，它就使用 `int16_t` 存储。如果后续加入了一个 `int32_t` 范围的数，`intset` 会自动升级（upgrade），将数组中所有元素都转换成 `int32_t` 类型，并重新分配内存。由于是有序的，查找元素可以使用二分查找，效率较高。添加和删除元素可能需要移动数组中的其他元素，但在元素数量较少时，这种开销是可以接受的。相比于使用哈希表（`hashtable`）作为 Set 的底层实现，`intset` 在满足条件时更加节省内存。

            1. `encoding` (编码方式) :
               - 这个字段决定了 `intset` 中每个整数占用的字节大小。它可以是 `int16_t` (2 字节), `int32_t` (4 字节), 或 `int64_t` (8 字节)。
               - Redis 会自动选择能够容纳集合内所有整数的最小编码方式。例如，如果集合中最大的整数可以用 16 位表示，Redis 就会使用 `int16_t` 编码。如果后续加入了一个需要 32 位才能表示的整数，`intset` 会自动升级其编码到 `int32_t`。
            2. `length` (长度) :
               - 这个字段表示 `intset` 中存储的整数的个数。
            3. `contents[]` (内容) :
               - 这是一个连续的内存区域，也就是你所说的“整数数组”。它紧凑地存储了集合中所有的整数。
               - 非常重要的一点是：这个数组中的整数是按照从小到大的顺序排列的。 这个有序性使得查找操作（例如判断一个整数是否存在于集合中）可以通过二分查找来高效完成。
         2. 否则使用 Hash 表
   5. Zset
      1. 集合个数小于 128，且每个大小小于 64 字节，用 Listpack
         1. zset 底层现在是用 listpack 来实现的，ListPack 被设计出来解决 zipList 的级联更新问题，并替换 zipList 来作为 Hash 和 zset 的底层数据结构

         - 键值在 Listpack 中的存储方式：当 Hash 使用 `listpack` 编码时，键和值是成对连续存储在 `listpack` 中的。`listpack` 内部是一系列 entry（条目）。对于 Hash 来说，这些 entry 的排列方式是：`[key1, value1, key2, value2, key3, value3, ...]`
           - 每个 `key` 是一个 `listpack` entry。
           - 紧随其后的 `value` 也是一个 `listpack` entry。
           - 这些 entry 一个接一个地排列。
      2. 否则用跳表
2. 跳表

   1. 跳表的实现：
      1. 每个节点的 level 是随机生成的，生成随机数，小于 0.25 则增加一层，大于时结束，最高 64 层
      2. 在第一层形成完整的双向链表
      3. 跳表的遍历顺序：
   2. 为什么选择用跳表而不是 B+ 树或者红黑树：
      1. 内存和访问模式的区别：
         1. B+：
            1. 磁盘友好，减少 IO 数适合范围查询
         2. 跳表：
            1. 内存友好：
            2. 插入删除简单，不需要维护树的结构
      2. 实现复杂度的区别：
      3. 性能对比：
         1. 跳表的内存占用更小
3. 为什么选择 Redis 做缓存，而不是 Memcached 或其他？（性能、数据结构、持久化、生态等）

### Lua 脚本

1. Lua 脚本为什么可以保证原子性

   1. 语雀：为什么 Lua 脚本可以保证原子性？
2. 写一写：

   1. 参数分为 KEY 和 ARG，自己传入

```
`-- KEYS[1]: 库存 key`
`-- ARGV[1]: 需要扣减的数量`
`-- ARGV[2]: 库存最小值(通常为 0)`
`local key = KEYS[1]`
`local quantity = tonumber(ARGV[1])`
`local minStock = tonumber(ARGV[2])`

`-- 获取当前库存`
`local currentStock = tonumber(redis.call('GET', key) or "0")`

`-- 检查库存是否充足`
`if currentStock < quantity then`
`-- 库存不足，返回-1`
`return -1`
`end`

`-- 检查扣减后是否会低于最小值`
`if (currentStock - quantity) < minStock then`
`-- 扣减后低于最小值，返回-2`
`return -2`
`end`

`-- 执行扣减操作`
`local newStock = redis.call('DECRBY', key, quantity)`

`-- 返回扣减后的库存值`
`return newStock`

```

### 线程模型

1. Redis为什么不用新线程来进行后台监视和更新
	1. 为了cow不影响主线程，以及不共享内存，方便AOF重写和RDP存储相应内容

2. redis的多线程
	1. 后台有处理关闭文件、AOF刷盘的线程

### 大key

1. 保持缓存60条点赞和30条活动会造成redis的大Key吗？
	1. 不会：https://xiaolincoding.com/redis/base/redis_interview.html#redis-%E7%9A%84%E5%A4%A7-key-%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86

### 发布订阅机制

1. redis内部实现
	1. 服务器内部维护字典，key为频道名，值为订阅列表
	2. 遍历表，通过websocket来发送消息
	3. 是非持久化的

### 内存淘汰和过期淘汰机制

### Redission

1. reddission什么时候用，优点缺点，为什么我们用
	1. 主要是引入它的看门狗机制，因为AI翻译的响应时间不好判断

2. 他的分布式锁是如何做的
	1. 在内部实现一个hash
		1. 存放持有锁的线程ID
		2. 锁的重入次数
	2. 锁竞争失败：
		1. 非公平锁：
			1. 通过订阅redis 的pub/sub chennel
			2. 竞争失败的线程会进入等待状态，不会自旋
		2. 公平锁：
			1. 额外使用一个List作为等待队列
			2. 用pub/sub发送消息唤醒等待队列

3. 看门狗机制
	1. 语雀：Redisson的watchdog机制是怎么样的？
	2. 看门狗如何检查是否还在使用这个锁：
		- 如果持有锁的 Java 线程正常结束，它会调用 `unlock()`，锁会被释放，看门狗任务也会被取消。
		- 如果持有锁的 Java 线程异常终止或者 JVM 崩溃，那么这个线程对应的看门狗任务自然也就停止了。这样，锁就不会再被续期，达到其原始的 TTL（或最后一次续期后的TTL）后，就会自动被 Redis 删除，从而允许其他线程获取该锁。
		- 所以，"线程还在使用" 的判断间接通过看门狗的续期动作来体现：只要看门狗在为这个 `uuid:threadId` 对应的锁续期，就意味着 Redisson 认为这个线程（或代表它的客户端实例）还在使用这个锁。
	3. 锁泄漏问题：
		1. 如果线程崩溃，且没有在finally块中unlock，且RedissonClient 实例和JVM没有崩溃，那么看门狗就会无限给这个已经崩溃的线程续约锁
			1. `RedissonClient` 是一个 Java 对象。它代表了你的应用程序与 Redis 服务器建立连接的客户端
			2. 看门狗线程是由 RedissonClient 调用的Redisson 内部的定时器线程

## 定时任务

![](static/B6AGbZn0TopC0SxNtmscOVLynJc.png)

1. 定时任务如果失败了该怎么办
	1. 通过带指数退避+抖动的方式重试，并且写日志

### 批量更新

![](static/BoarbFxiEoFSOgxGuGPcp5yknuc.png)

1. foreach 与 sqlSession的区别
	1. 前者是字符串拼接，其实还是一次一次单次执行。都是复用同一个数据库链接。后者可以调用mysql的识别批量操作和优化

## 消息队列

### 通用问题

1. 挂了怎么办

2. 没收到怎么办

### RabbitMq

## 定时任务

### XXL

## 设计模式

### 状态模式

![](static/OiWEbFM7QogLC8xpftGc7ofHnJe.png)

# 简历综合部分

![](static/BUc1bsU27o17J5xcNfQcgmxQn0c.png)

![](static/Ysd0bzFMdo5Kdkx5LzEca1Z5nAe.png)

![](static/JKDTb6Lc3o8rhXx7VGScpAnJnnt.png)



## 一致性与并发

![](static/P5JwbenEvowVYHxNXWQcJ6PGnMg.png)

1. 为什么要用redis
	1. 最开始的需求是我们的点赞，由于它是多属性点赞吗？所以的话考虑到后期拓展点赞表情的情况，所以就没有办法直接到那个表里面去统计每一个表情的点赞数量是多少，然后如果没有这个统计的话，就需要每次去点赞记录里面去查，然后来把这个加起来这样的话就感觉很愚蠢，所以说就用了一个redis。其实这一步的话，当时也有考虑用替代方案里面说弄一个本地缓存像Map或者是说像我们现在用的就是把这个统计之后变成一个json序列化成string来存储。但是由于这样做的话，stream没有办法直接加减就会导致并把问题需要加锁那考虑到性能需求的话就直接用Rez，因为Riddick的话是直接原子操作在哈市里面加减数量。，不需要考虑到并发问题，同时如果Reise里面过期了的话，也可以根据分布失所来防止缓存击穿。

2. 为什么有了redis还要使用json表？
	1. json表相当于一个二级缓存，当Redis失效时可以防止每次查询都需要从记录表中读取数据出来累加

3. 什么是缓存与数据库的双写不一致问题？请描述可能发生不一致的场景。
	1. 指的是更新数据库和缓存时，由于顺序或者并发问题，导致的数据库和缓存数据不一致。核心问题： 数据库和缓存是两个独立的系统，更新它们的操作通常无法保证是 原子性 (Atomic) 的。要么都成功，要么都失败，这很难完美实现。
	2. 用户A点赞的同时，缓存出现问题更新失败，用户B刷新帖子表查看点赞数，此时用户B查看到的是A生效前的点赞数
	3. 并发导致的不一致（无锁或者锁粒度不对的情况）

4. 更新缓存采用删除原始缓存的方式，为什么删除缓存通常优于更新缓存？ 
	1. 因为删除只需要完成一个原子操作就行了，而更新要保证取出和写入。同时，直接删除可以保证最终一致性，因为总是会从数据库中重建缓存。
	2. 但是我们的结构可以直接存为hash，有原子操作，就可以不用删除

5. 删除的时候有人读取，这不就击穿了吗？如何限制？
	1. 在redis中使用一个key来作为分布式锁，保证只有一个线程可以更新缓存
	2. 使用redis加锁或者用synchronize锁（双重检查）
		1. 当前暂时是单机单实例状态，可以使用synchronize锁，但是拓展到多实例了就应该用redis来加锁

## 限流与回调

BR：什么情况用，可能有哪些问题，该如何解决

为什么。怎么做的，有点缺点

![](static/LGonbe6ego3tefxsmvpcY1WrnCd.png)

1. 第三方AI接口、流量限流
	1. 令牌桶等限流方案
	2. 限流响应状态码
	3. 接口服务器崩了怎么办（同redis）
		1. 降级
		2. 熔断
	4. 被限流了怎么破解
		1. 看响应码，sleep之后调用
	5. 超时
	6. 异步调用
	7. 接口状态调用用CAS

2. 是不是可以做一个API池，当一个API无法使用时，调用其他的，或者一次调用多个API，但是这样返回的结果可能不一样，而且响应时间也可能不同

# 简历业务部分

##   校园墙模块

### OSS直传

1. 流程：后端存储ID和KEY，生成短

### 翻译功能

![](static/GYddb5X0IoecyLx4W0Gc8cLLnxe.png)

1. **BR**：什么情况用，可能有哪些问题，该如何解决为什么。怎么做的，优点缺点
	1. 跨服务的事务
		1. 分布式事务的方案（找出四种的优点缺点，以及为什么用本地消息表）
			1. 实现强一致性：
				1. Saga AT：
					1.  Seata 框架提供的一种无侵入的分布式事务解决方案，它基于 2PC 模型进行了改进，主要面向关系型数据库
					2. 核心思想：
						1. 一阶段 (业务SQL执行与注册分支) :
							- TM (Transaction Manager - 事务管理器) : 向 TC (Transaction Coordinator - 事务协调器) 申请开启一个全局事务，TC 生成一个全局唯一的 XID。
							- RM (Resource Manager - 资源管理器) :
								- 代理数据源，拦截业务 SQL。
								- 解析 SQL 语义，找到业务 SQL 要更新的数据。
								- 在执行业务 SQL 之前，查询数据并保存为 "before image" (数据前镜像)。
								- 执行业务 SQL。
								- 在执行业务 SQL 之后，查询数据并保存为 "after image" (数据后镜像)。
								- 插入回滚日志 (undo_log)，包含了 before image、after image、XID、BranchID 等信息。
								- 获取全局锁: 为了保证隔离性，RM 会向 TC 申请对该行记录的全局锁。如果锁已被其他全局事务持有，则需要等待。
								- 提交本地事务: 上述操作（业务SQL执行、undo_log插入）在同一个本地事务中提交。
								- 向 TC 注册分支事务，报告本地事务执行成功。
						2. 二阶段 (提交或回滚全局事务) :
							- 全局提交:
								- 如果所有分支事务在一阶段都成功，TM 通知 TC 提交全局事务。
								- TC 通知所有涉及的 RM "异步" 删除对应的 undo_log 记录（因为本地事务已提交，数据已持久化），并释放全局锁。
							- 全局回滚:
								- 如果任何一个分支事务在一阶段失败，或者 TM 主动发起回滚，TM 通知 TC 回滚全局事务。
								- TC 通知所有涉及的 RM 回滚其分支事务。
								- RM 收到回滚指令后，找到对应的 undo_log 记录，根据 "before image" 生成反向补偿 SQL 来恢复数据。
								- 完成数据恢复后，删除 undo_log 记录，并释放全局锁。
					3. AT 模式的优缺点:
						- 优点:
							- 无侵入: 对业务代码几乎没有侵入，开发者只需关注业务 SQL。
							- 自动补偿: Seata 自动生成回滚日志和补偿逻辑。
							- 性能较好: 相对于 XA 模式，一阶段直接提交本地事务，锁的粒度也更细（行级锁）。
						- 缺点:
							- 依赖数据库类型: 目前主要支持关系型数据库。
							- 有性能损耗: 额外的镜像查询、undo_log 写入、全局锁的竞争。
							- 有脏写风险 (Seata 通过全局锁解决) : 如果没有全局锁，在分支事务提交后、全局事务提交/回滚前，若有其他事务修改了同一数据并提交，则可能导致数据不一致。Seata 的全局锁机制主要就是为了防止这种情况。
							- 不适合长事务: 因为全局锁会长时间持有，影响并发。
				2. 两阶段提交 (2PC - Two-Phase Commit) / 三阶段提交 (3PC - Three-Phase Commit)
					1. redoLog和binLog的两阶段提交
			2. 实现最终一致性：
				1. TCC（刚性事务与柔性事务）
					1. 针对每个需要进行分布式事务管理的服务，开发者需要提供三个接口：Try、Confirm 和 Cancel。（侵入式的）
					2. 运作流程:
						1. Try 阶段:
							- 尝试执行业务。
							- 完成所有业务检查（一致性、业务约束等）。
							- 预留业务资源（例如：冻结库存、冻结金额、预分配ID）。
							- Try 操作必须是幂等的。
							- 如果 Try 成功，则等待协调器的下一步指令；如果失败，则直接认为该分支事务失败。
						2. Confirm 阶段:
* 仅当所有参与者的 Try 操作都成功时，事务协调器才会通知所有参与者执行 Confirm 操作。
* Confirm 阶段真正执行业务，使用 Try 阶段预留的资源。
* 例如：将冻结的库存实际扣减，将冻结的金额实际转出。
* Confirm 操作必须是幂等的。
* Confirm 操作通常情况下应该成功（因为 Try 阶段已经检查和预留了资源）。如果 Confirm 失败，需要引入重试机制，或者人工干预。
						3. Cancel 阶段:
							- 当任何一个参与者的 Try 操作失败，或后续 Confirm 失败（虽然少见但可能发生）时，事务协调器会通知所有已成功执行 Try 操作的参与者执行 Cancel 操作。
							- Cancel 阶段释放 Try 阶段预留的业务资源。
							- 例如：解冻库存，解冻金额。
							- Cancel 操作必须是幂等的。
							- Cancel 操作也需要保证成功，不成功则持续重试。
					3. TCC 模式的优缺点:
						- 优点:
							- 不依赖特定数据库: 可以在不同类型的数据库、甚至非数据库资源（如消息队列）之间实现事务。
							- 不长时间锁定资源: Try 阶段预留资源通常时间较短，本地事务提交快，Confirm/Cancel 阶段异步执行，并发性能较高。
							- 灵活性高: 由业务方自定义 Try、Confirm、Cancel 的逻辑，可以应对复杂的业务场景。
							- 最终一致性: 通过补偿机制保证。
						- 缺点:
							- 业务侵入性强: 需要开发者为每个服务编写 Try、Confirm、Cancel 三个接口，开发和维护成本高。
							- 实现复杂: 幂等性、空回滚（Try没执行就调用Cancel）、悬挂（Cancel比Try先执行）等问题需要仔细处理。
							- 数据一致性问题: 在 Try 和 Confirm/Cancel 之间，数据处于中间状态，可能会被其他业务读取到（没有严格的隔离性）。
				2. Saga（长时间运行事务）
					- 原理: 将一个长事务拆分成多个本地事务，每个本地事务都有一个对应的补偿操作。Saga 执行器会顺序调用每个本地事务，如果某个本地事务失败，则会反向调用前面已成功执行的本地事务的补偿操作。
					- 优缺点：
						- 优点:
							- 一阶段提交本地事务，无锁，性能高。
							- 允许业务逻辑的灵活性，补偿操作可以根据业务需求定制。
						- 缺点:
							- 不保证隔离性（因为本地事务已提交，补偿操作执行前，其他事务可能已读取到中间状态）。
							- 需要为每个操作设计补偿逻辑，开发成本高。
				3. 最大努力尝试
					1. 原理：将消息发送给消息队列之后，多次尝试发送，如果不成功，则不再发送
					2. 场景：此处不适用，因为有API切换机制，就没必要反复重试了
					3. 优缺点：
						1. 优点：
						2. 缺点：
							1. 存在重复发送或者丢消息的可能
					4. 什么时候用：
						1. 可以接受丢消息
				4. 本地消息表（结合翻译表里）
					1. 原理：语雀：如何基于本地消息表实现分布式事务
					2. 我的场景：调用翻译接口和写翻译纪录表在同一个事务中，同时设置事务的状态为 等待中，在同一个线程中等待API返回内容，这里不用担心大量的长时间链接耗尽链接池，因为在查询前会上锁，所以最多一个帖子占用一个链接。同时这里API有失败之后转换的机制，所以不用担心会G，做状态只是为了万一全部都G了。可以通过创建时间来做一个检查
					3. 优缺点（理论和对应场景的）：
						1. 优点：
							1. 对代码的侵入性不高
							2. 不需要Mq支持事务消息
						2. 缺点：
							1. 需要设计消息发送机制以及相应的上下游异常处理和幂等处理
								1. 下游如何确定幂等：
									1. 上游在消息体中携带一个UUID供下游做幂等，也可以再加上version来让乐观锁使用
								2. 下游如何通知上游：
							2. 需要定时扫描本地消息表，影响性能
								1. TODO 讲讲定时扫表会对性能造成哪些影响以及为什么
								2. 消息堆积，扫表满
									1. 可以通过多线程并发扫表和建立数据库索引来解决
								3. 集中扫表会影响正常业务
									1. 可以通过扫表备库的方式进行解决
										1. TODO 数据库的主从同步等
								4. 存在延时问题
									1. 可以通过用延迟消息的方式来实现
					4. 什么时候用：
						1. 对一致性要求不是特别高，但是也不能丢的情况
						2. Mq不支持事务消息
						3. 需要持久化或者对账
	2. Mq发邮件等 调第三方接口 - 》 分布式事务
		1. 如何保证消息一定能发送到MQ
			1. 从生产者到exchange：
				1. rabbitMQ会通过confirm机制，返回ACK或者NACK给生产者吗，生产者可以通过注册Listener 来处理ACK和NACK，比如修改本地事务表的状态
			2. 从exchange到queue：
				1. 通过持久化机制
					1. durable参数持久化： 交换机 、 队列 、 绑定关系
					2. 在创建了持久化队列后，可以设置消息的deliveryMode来将消息发送到持久化队列中，直接写入磁盘
			3. 从队列到消费者：
				1. 消费者向Mq发送ACK，Mq收到ack之后才会删除消息。如果出现异常就发送nack或者ACK超时，，这样MQ就会重新投递
			4. mq的持久化是异步的，先内存再写入磁盘，写入之前还是会丢失，所以需要本地消息表加轮询的机制来重投
		2. mq如何防止重复消费：
			1. 生产者生成一个UUID放到消息体中，消费端获取到这个uuid之后就可以做幂等处理
	3. 第一次插入本地消息表时，先查本地事务表，无记录，插入新纪录，并设置状态。
		1. 此时加分布式锁，未获得锁的线程可以返回后短轮询
			1. 同步改异步：
				1. 推：
					1. SSE
					2. websocket
				2. 拉：
					1. 长轮询
					2. 短轮询
		2. 小并发量，数据库抗的动，可以直接数据库锁（推荐）
	4. 提示词调优：
		1. 角色限定
		2. 格式化输入（提示词的格式）
		3. COT（翻译的COT如何构建的）
		4. 迁移学习

2. 流程：
	1. 目前：
		1. 先查询缓存和数据库中是否有数据，如果没有的话，获取分布式锁（此处如果已经有分布式锁了，那么立刻返回，请重试），然后是只用了一个免费的API，如果报错，那么就直接返回前端，由前端调用原本的翻译。后端和Redis中只会存储大模型翻译的结果。这里同步调用，不选择异步调用，因为没有必要，且就算异步了，也没其他事情干了。除非结束连接，通过其他方式进行消息推送。（有哪些异步通知的方法）。调用时使用分布式锁，防止多个线程同时调用一个帖子的翻译，同时也保证幂等性。（有没有其他方案）。得到翻译结果之后，把帖子uuid、目标语言、翻译内容，翻译时间记录到数据库。并在redis的帖子Hash中，增加翻译记录，key为语言，value为内容。
	2. 后续：
		1. 打算添加两个API，作为切换，用一个内部类来保存每个API、BaseURL和模型名字以及状态，通过@ConfigurationProperties(prefix = "ai.openai") 来进行配置。然后用一个查询可用Key的方法来提供Key。

3. 流程：
	1. 大量并发请求同一帖子翻译：
		1. 前端请求进入后，先查询redis中是否存在该内容，不存在去查数据库，数据库没有记录则获取分布式锁，调用接口进行翻译，数据库/redis显示正在处理，则前端设置最大轮询次数进行轮询redis。处理成功之后插入数据库和redis，并解锁。如果调用失败，则在同步线程中进入APIkey的更换，最后有谷歌翻译进行兜底（但是此时设置翻译的状态为谷歌翻译，后续用定时任务查出所有谷歌翻译的进行AI翻译，并写入缓存中）
		2. 备选方案：1. 后端异步调用，前端轮询 2. 同步调用，不好，为什么 3. 异步调用 + web sock ，最好，如何实现的，原理是什么
			1. 选用：异步➕前端轮询➕分布式锁
				1. 怎么实现：
					1. 分布式锁过期时间与后端API调用失败响应时间相同
			2. 优缺点：
				1. 同步调用
					1. 缺点：
						1. 长时间占用tomcat的请求处理线程，如果有大量并发请求，可能耗尽web服务器请求线程池链接数量
						2. 同步调用，如果有并发请求的话，只能直接返回或者在后端轮询，大量并发的情况下，一个卡住了，其他都要跟着等待直到指定时间
				2. 异步调用 + 前端轮询
					1. 缺点：
						1. 轮询频率控制：太快增加服务器负载，太慢用户感觉延迟高和无限轮询问题
						2. 如果一个异步任务掉了，这样数据库里那一条就永远是等待中，该如何解决
						3. 大量并发下的轮询造成的缓存穿透问题
							1. 这个地方不会造成穿透，因为都需要获得分布式锁再执行
				3. 异步调用 + web socket 
					1. 缺点：
						1. 技术复杂
			3. 什么情况下使用：
			4. 可能有哪些问题，如何解决：
	2. 大量并发请求不同帖子翻译：使用Qwen/Qwen2-7B-Instruct，免费的RPM1000，TPM为50000
		1. 限流：使用令牌桶的方式来限流

4. 可能问的问题：
	#### 异步调用来等待服务器响应的方案：（不同调用方式）
1. 同步（前端阻塞调用）
	1. 前端Http可能因为超时而断开（在建立连接之后，通常是30秒到5分钟）
2. 异步：此处推荐用SSE
	1. 前端轮询：
		1. 实现：
			1. 返回一个任务ID（翻译表中消息和目标语言那条记录的UUID）
			2. 前端递增的轮询
		2. 优缺点：
			1. 资源消耗，频繁建立连接
	2. 后端主动通知：
		1. WebSocket：
			1. 实现：
				1. 建立持久的WebSocket连接
			2. 优缺点：
				1. 实时性高
				2. 但是消耗资源
		2. Server-Sent Events (SSE)
			1. 实现原理：
				1. 建立连接：前端向后端发起一个特殊的HTTP请求，后端保持此连接打开，形成一个从服务器到客户端的单向数据流。
				2. 发送请求：通常，翻译任务的提交还是通过一个普通的HTTP POST请求。后端在开始处理后，可以通过SSE通道向前端发送进度更新或最终结果。
				3. 主动推送：翻译完成后，后端通过SSE连接将结果作为一个事件发送给前端。
			2. 优缺点：
				1. 优点：
					- 实时性较好：虽然是单向的，但能实现服务器到客户端的实时推送。
					- 实现相对简单：相比WebSocket，SSE的API更简单，基于标准的HTTP。
					- 自动重连：浏览器通常会自动处理SSE连接断开后的重连。
				2. 缺点：
					- 连接数限制：浏览器对同域名下的并发HTTP连接数有限制（SSE也算一个连接）。
					- 某些代理或防火墙可能不支持流式HTTP响应。
		3.  回调通知 (Webhook)
			1. 工作原理：
				1. 前端将翻译请求发送给您的应用后端A。
				2. 后端A调用一个外部的翻译服务B（或者一个内部的异步处理模块），并在调用时提供一个回调URL（这个URL是后端A上的一个接口）。
				3. 翻译服务B异步完成翻译后，会向之前提供的回调URL发送一个HTTP请求，将翻译结果通知给后端A。
				4. 后端A收到回调后，再通过某种机制（如上述的WebSocket、SSE，甚至再结合前端轮询后端A）通知前端。
			2. 优缺点：
				- 优点：
					- 解耦：非常适合与第三方服务集成，或者在微服务架构中进行异步任务处理。
					- 可靠性：对于非常耗时的任务，这种方式比较健壮。
				- 缺点：
					- 复杂度高：涉及多个组件间的协调。
					- 回调URL需要公网可访问（如果翻译服务B在公网）。
					- 最终还是需要后端A与前端之间的通信机制。
	#### 需不需要做本地消息表来保证完全调用成功：
	#### 如何检查服务是否超时，崩了之后怎么办
1. 参考资料：
	1. 语雀：
		1. 第三方接口不稳定经常超时，如何处理三方接口异常不影响自己接口
		2. 调用第三方接口支付时，第三方接口显示支付成功，但是在调用方显示支付失败，问题可能出在哪里
2. 方案：
	1. 写脚本测试，1000字平均响应时间是60s以内
	#### 接口limit了或者服务坏掉了，如何降级或者切换API
1. 目前的想法是：limit了，则拒绝当前翻译请求，设置数据库状态为请求失败（请求成功了再插入数据到redis，redis中查不到都需要来数据库，由此进行重试），并后台执行一个切换API的线程，等待分布式锁过期之后再次进入请求。
	1. 在切换API的线程里判断，如果全部API都不可用，微信机器人发报警信息，并且想办法通知前端直接调用谷歌的翻译接口
2. 问题：
	1. Spring AI 如何切换API，目前想的是做一个循环
		1. 用配置类映射文件中的key等配置，然后对更新API方法进行加锁，并且有一个定时任务来监测挂掉的任务是否恢复。
		2. Key设置优先级，最后一层是谷歌翻译，可以作为翻译兜底
	2. 如果是多实例部署，该如何通知API状态的变化
		1. 通过redis的发布订阅模式
	3. AI有哪些通用接口，Spring AI 是怎么处理的
		1. 有不同的标准，Spring AI 通过配置的方式适应不同的标准
	4. 熔断和降级的流程代码实例
		1. 不需要熔断和降级，因为我们的翻译调用次数并不是很多，所以很难确定一个失败次数。因此选择捕捉API返回错误和超时的方式进行API切换
	5. API切换如何保证只有一个线程在执行
		1. 使用分布式锁处理
	6. 选择同步切换还是异步切换
		1. 选择同步切换，因为用户多等一会没事，但是翻译失败了需要手动点击重试体验就很不好了
	7. 如果被限流了，怎么发现，该如何处理
		1. 检查Spring AI 的抛出的错误：RateLimitException 和 AiServerException，然后切换API
	#### 接口如何限流，调用的限流方案的原理（如令牌桶之类的）
1. 参考资料：
	1. 语雀：防止接口被恶意刷流量，除了限流还应在代码层面做哪些防护？
2. 使用限流算法：令牌桶
	1. 目标：防止超过API的 rate limit，同时限制并发，但是并发测试中，500并发下，有94%的成功率，同时返回错误大部分是DNS解析失败，考虑到RPM只有1000和我们的用户量，不考虑使用多个API，但是要考虑API挂掉之后的降级。
		1. 使用令牌桶：令牌桶以恒定速率向桶中添加令牌，可以满足每分钟都有可用额度的需求，同时相比较于滑动窗口，还可以积累之前未用的请求或者token数，因此更适合当前场景
	2. 备选：固定时间窗口、滑动时间窗口
	#### 为什么会DNS解析失败：
1. 
	#### redis缓存，用不用数据库来持久化，表怎么设计
1. 表设计分为帖子ID，目标语言，目标语言代号，原内容，对帖子ID和目标语言建立索引
2. redis中用hash存储，设置过期时间（查询时查出所有的语言翻译，放到hash中）
	#### 提示词优化
1. 思维链cot
2. 迁移学习：给几个情景例子

### 点赞功能

![](static/MzxJbvKm0o0RlrxyVoycoMfvnHc.png)

1. 流程：
	1. 最终：先上锁，再更新Redis，再更新两个表
	2. 思路转变：
		1. 原来是：
			1. 先插入数据库，再去更新缓存，因为用户ID和帖子ID和点赞类型做了一个联合唯一索引，单用户单帖子的并发量很少，所以完全可以用数据库去抗并发。而且Redis不知道是否这个是点赞过了，如果Redis放前面，那就要加锁，再查询数据库，再增加Reids和插入数据库。现在这样就不用加锁了，数据库插入成功之后，再更新Redis。这里使用Redis的目的是供多个线程去获取，抗并发。
		2. 但是考虑到：
			1. 如果Redis更新失败，且重试失败了
				1. 解决方案：
					1. 不可能说回滚Mysql
					2. 可以用本地消息表，但是在这里太夸张了，专门为了少用个锁来创建一个失败消息表也太夸张了，所以改用分布式锁
					3. 如果要解决，还可以直接删除缓存
			2. 同时，为了在帖子表中增加JSON字段作为缓存，就需要上锁来更新数据库，这样就先上锁，更新Redis，再更新两个数据表。

**BR：**

#### JSON 后期拓展性

#### 单用户点赞的幂等性选分布式锁，粒度小，适合
1. 有状态-》CAS
2. 无状态-〉加锁

#### 用户点赞，帖子用数据库锁，单帖子并发量不大，没必要上分布式锁那么麻烦（讲清楚
1. 数据库锁可以看选CAS还是悲观锁，由重试次数决定，等待时间长，太多重试，就用悲观锁
	1. 看数据库悲观锁与redis分布式锁悲观锁的区别

#### 准备一下大公司的合并写库方案（同步阻塞式改异步非阻塞式）

#### 接口幂等：
1. 幂等问题都是 1锁2判3更新：
	1. 为什么不用数据库唯一性约束来做幂等控制
		1. 依赖insert来触发
		2. 依赖catch 来做流程控制
			1. 异常可能会随着版本改变而改变
			2. 同时捕获异常会影响事务的回滚
				1. 用try catch捕获和处理了异常，事务不会发生回滚
		3. 导致并发都由数据库来抗

其他问题：

#### 你是如何设计数据库表来存储多态点赞数据的？字段有哪些？为什么这样设计？
1. 通过fastJson库将Json转换为varchar存储，这样可以方便拓展表情

#### 校园墙的帖子是用什么方式存在redis中的？如何更新的呢？
1. hash+zset作为排行榜
2. 直接用原子操作更新hash和排行榜

#### 直接查询点赞记录字段来统计点赞数据会很耗时间吗？
1. 后端统计本身很快，瓶颈在于每次都需要去遍历记录表

#### 点赞过程中，数据库和缓存是如何更新的，可能出现哪些问题
1. 通过事务，先插入点赞记录，再post修改帖子的json，最后删除缓存。这样可以保证数据源是准确干净的，短时间内缓存的不一致可以接受。

#### 通过唯一索引，锁住点赞用户和点赞帖子，防止插入重复点赞数据
1. 捕捉mysql错误吗1062

### 分页功能

![](static/PgPKb8yszoxaHLxmh4DcdiUTn8g.png)

1. BR：
	1. 深分页
	2. 数据重复
	3. 两种分页方法的区别

2. 缓存逻辑：
	
3. 排序
	1. 按时间排序
	2. 按点赞数量排序

#### 为什么选择游标分页？
1. 最开始没用redis，根据排序查看时，会出现数据的重复或者丢失，且数据量大了之后每次都需要查询很多内容，考虑到我们不需要跳转，所以采用游标分页。
	1. 有redis之后，同样需要时间➕点赞数来避免相同点赞数的问题，直接zrange即可
2. 预防深分页
	1. 反正我们也不支持页码跳转

#### 缓存的更新策略是怎样的？zset和hash的更新策略是什么
1. 通过zset+lua脚本，保持缓存60条点赞和30条活动
	1. 每天晚上计算活动热度时，同时更新帖子和活动两个模块的排行榜中的数据的过期时间，更新为48h
2. 因为hash和zset都存在原子操作，所以在redis的单线程机制下，只要数据库更新正确，就不存在并发问题。但是为了健壮性，可以用定时任务更新缓存。
	1. zset中的不需要定期删除，因为当前的redis可以支持上亿的小key，我们的软件达不到这个量级
	2. zset如果实在要清理，可以每周删除重建
3. 分页是通过redis来实现的，那么zset中的不够了去数据库找，此时代码逻辑是怎么样的，假如翻到了最后一页呢？
	1. 通过判断redis返回的list的数量与pageSize对比，不够就去数据库拉
4. 更新的时候使用原子操作，但如果那个
	1. 那我在更新点赞数的时候，假如该条帖子不在redis中（虽然我能看到这个帖子它就一定被加载到redis中了，但假如redis加载失败了。）那么我就直接加载数据库中的到redis里，



### 热度排序

![](static/QUIVbxEomolu8txtWc6ceL8vnUd.png)

#### 热度计算公式

> 参考资料：https://www.jianshu.com/p/fb454a4b383d

![](static/Z8tXbBSGGoY4MExU9wEcE5KfnJb.png)

同时将当前时间戳作为小数部分来排序相同热度项（1-当前时间）


##### 离线计算的具体流程是怎样的？是从数据库捞取数据 -> 计算热度 -> 更新排名 -> 写入缓存吗？这个过程有没有什么难点？
1. 选择单线程更新还是多线程更新？
	1. 单线程，使用mybatis的sqlSession批量读取和更新，减少链接时间和次数。同时避免多线程的并发等问题
	2. 简历联合索引实现索引下推，避免频繁回表

##### 计算过程中，如果某个活动的数据发生了变化（比如有人参与了拼团），这次离线计算会使用变化前还是变化后的数据？这对结果有什么影响？
1. 使用变化之前的数据，离线计算的流程是，从数据库中一次性读取数据，然后放到内存中计算，再批量写入数据库，再将最热门的top10写入缓存。本来也是一天一算，数据变化记入第二天即可。

BR：

#### 定时任务怎么实现（怎么用Spring注解，实现流程）
1. 单机和多实例

##### 定时任务用Mq怎么做

### 活动状态流转

#### 热度更新方案

![](static/Uwx0bJoBkoBIP6xD3dpc2RG8nBd.png)





拼团帖子排序分为：

拼团热度影响因素：

BR：

#### 主动是什么，被动是什么

采用 **被动更新 **+ **定时任务** 的方式更新热度值，避免因频繁查看导致的多次更新对数据库造成压力，同时避免冷门活动热度一直不更新导致沉底。

- 被动更新：用户点赞、参与活动、评论、收藏时，更新数据库记录的同时修改 redis Zset 的 score 值
	- 定时任务：每天12:00AM，并依据查看数和活动时间，更新全部进行中活动的热度值。

1. redis缓存的设计
	1. hash使用活动 uuid+创建者uuid，防止同一用户创建相同活动
	2. zset用热度值+创建时间创建排行榜，用lua脚本检查是否达到最大值，若达到最大值则使用zpopmin原子操作弹出最小值
		1. zpopmin作为原子操作，替代了zrange+zrem
		2. zpopmin删除排行榜中热度最低的和排行榜中时间最久的
	3. 如何定时更新redis中的缓存内容
		1. 在数据更新时更新
		2. 每天晚上计算热度时更新

#### 类似Redis的过期策略，是怎么模仿的

#### 活动关闭

1. 参考资料：
	1. 语雀：
		1. 订单到期关闭如何实现

### 拼团活动创建与报名

1. 流程：
	1. 创建流程：
		1. 商家创建活动之前，去redis和数据库中检查是否有相同名称的未结束活动
			1. 防止刷存在感的，去找他时耍赖
		2. 商家创建活动之后，计算其热度值之后，写入数据库和redis，同时创建redis的按热度值和按时间的zset
			1. 每天晚上定时任务更新这些排行榜内的缓存的TTL
		3. 根据用户操作以及每天晚上更新来流转活动状态和活动热度
		4. 活动结束之后，更改数据库中的活动状态，并且删除缓存中的内容

2. 避免用户多次创建相同活动：
	1. 技术选型：
		- **使用唯一请求标识**
		前端在发起创建活动请求之前，先向后端获取一个唯一请求标识 token（可放在 Redis 中，设置一定TTL）；在提交请求时，携带此 token，后端进行校验，校验通过后即可“占用”该 token，并标记已使用。如果后续有相同 token 的请求再来，就直接返回“请求已处理”或报错，防止重复创建。
		- **活动业务唯一约束**
		用数据库的唯一约束来做，但是这里不好选择字段来建立唯一约束，如果存唯一请求标识的话没有必要（可以直接用redis）

#### 幂等和防止超卖

![](static/GubSbDjIvo5n23x2gdWcB4MNnVf.png)

1. 为什么要用redis，不用数据库联合索引唯一索引。为什么不用Synchronize
	1. Web 应用通常是分布式的: 现代 Web 应用，尤其是那些使用 Spring Boot 等框架构建并期望有合理流量（如我们的 3700+ DAU）的应用，几乎总是跨多个实例部署，以确保可用性和负载均衡。这意味着你不仅仅运行一个 Xplorer 应用的副本；你可能同时运行 2 个、5 个甚至更多相同的实例，可能在不同的容器（如 Docker）或不同的虚拟机上。
	2. 在单机环境下，用`synchronized`结合 concurrentHashMap 锁每个 ActivityID 对应的对象，确实能满足需求，但我选择 Redis 锁主要基于以下几点，同时我也用活动名称与用户 uuid 做了联合索引，从数据库层面进行兜底。
		1. **扩展性**：未来迁移到集群时无需改造。
		2. **细粒度控制**：可以按活动 名称 加锁。
		3. **健壮性**：支持超时自动释放，防止死锁。
		4. **可观测性**：方便监控锁竞争情况。
		5. **性能**：Redis 基于内存，性能更高，且不受 JVM GC 影响。
		6. **技术栈统一**：如果系统已用 Redis，复用比引入新机制更简洁。
	3. 以及我不想让用户重复创建名称相同的活动，synchronize只能解决并发问题，要防止用户创建相同名称，还需要依赖数据库联合唯一索引。

2. 防止超卖：
	1. 如何防止同时报名产生的超卖问题
		- 方案一：数据库悲观锁 (MySQL `FOR UPDATE`)
			- _评估：_ 考虑到你的日活和浏览量，高并发场景下悲观锁的性能瓶颈可能会比较明显，锁竞争激烈时会严重影响用户体验。虽然实现简单，但可能不太适合你的项目规模。
			- _推荐度：_ 低 
		- 方案二：数据库乐观锁 (MySQL `version`或 CAS)
			- _评估：_ 性能优于悲观锁，能保证数据一致性。但在高并发、高竞争场景下（例如抢购热门二手商品或最后几个拼团名额），会导致大量更新失败和重试，影响用户体验和系统性能。
			- _推荐度：_ 中等 (可以作为备选，但可能不是最优)
		- 方案三：Redis 原子操作 (Redis `DECR`/`Lua`)
			- _评估：_ 性能极高，非常适合高并发场景。需要将库存预加载到 Redis，并处理 Redis 与数据库的数据一致性问题（例如异步更新数据库）。你的项目中有离线计算热度的经验，这种异步处理的模式可以借鉴。
			- _推荐度：_ 高 (如果对性能要求非常高，且能接受最终一致性)
		- 方案四：Redis 分布式锁 (Redis + Redisson/其他库)
			- _评估：_ 你已经在项目中成功应用了分布式锁来解决点赞的并发问题，这表明：
				1. 你的项目中很可能已经集成了 Redis。
				2. 你具备使用和管理分布式锁的技术经验。
分布式锁可以在操作库存（无论是直接操作数据库还是结合乐观锁/Redis 原子操作）的关键代码段加锁，确保同一时间只有一个请求在处理特定商品的库存扣减。它提供了比数据库锁更好的性能，同时比纯 Redis 原子操作更容易保证与数据库操作的事务性（将数据库操作放在锁内）。
			- _推荐度：_ 非常高 (最推荐)

3. BR问题：
	- [ ] lua解决超卖问题，用了lua处理 少 卖 问题

### 活动发布前端COS直传图片

用户发布活动时，需要上传活动相关的图片。由于可能文件体积较大或上传量较多，采用**前端直传**到 COS / OSS 的方案，减少后端服务带宽占用。

1. 前端先向后端请求“上传签名”，后端根据用户信息或临时凭证生成短时效的**UploadToken**或**STS临时密钥，对文件大小、类型做服务端校验。**

2. 前端拿到签名后，直接向腾讯云 COS / 阿里云 OSS 发起请求，完成文件上传；

3. **回调：**前端上传成功后，会拿到文件的存储地址（URL），再带着此地址与其他活动发布信息一起提交给后端，后端写入数据库



## 榴莲配送模块：

BR:

![](static/LeK9banOroXoW7x4jJWcKsSsnld.png)

1. 与上面的活动更新做区别，消息队列与扫表的区别

2. 用MQ的缺点，跨进程分布式事务

![](static/N0U4bWlbEoXhG6x8X3zc9LKZnrF.png)

1. 为什么用List：

![](static/NfGgbpWOpowehZxtd0hcZ42hnmb.png)

1. 主动取消和被动取消的订单，怎么取消超时订单

2. 线程池批量更新

3. 什么时候用线程池，什么时候用mq做（区别在于跨没跨线程）

4. 如何限制总的并发量
	1. 定时任务扫描限制

