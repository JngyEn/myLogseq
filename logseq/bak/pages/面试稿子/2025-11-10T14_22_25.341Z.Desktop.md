
## 自我介绍

面试官你好，我来自厦门大学马来西亚分校，本科专业是计算机科学与技术。我主要的经历有两段，一段是在蚂蚁集团的后端开发实习，另一段是在学校和一个团队搭建了一个校园论坛App，目前有3000多的日活。我先从蚂蚁的实习经历开始讲吧。

我在蚂蚁的实习主要做两部分工作。第一部分就是您刚才提到的，最近比较火的AI Agent和工作流的搭建。另一部分是我们做了一个客服中台，对接东南亚最大的国际电商Lazada。我们作为客服中台，对接了他们原有的人工客服平台，并用我们自研的工作流替换了他们原本基于规则判断的客服机器人。

这个中台的模式是：先让用户和我们的AI客服聊天，当AI客服无法处理或用户情绪激动时，再将流量导向人工平台。我在这边主要负责了三个围绕优化用户和AI聊天体验的需求。

面试官您好，我毕业于厦门大学马来西亚分校计算机科学与技术专业。
我的主要经历有两段，一段是在蚂蚁集团的后端开发实习，另一段是参与开发一个校园论坛App。在蚂蚁集团的实习期间，我主要负责了两部分工作。第一部分是参与了新人入职引导AI Agent和工作流的搭建。另一部分是参与对接东南亚最大的电子钱包tngd的客服中台开发。我们作为客服中台，对接了他们原有的人工客服平台，并用我们自研的工作流替换了他们原本基于规则判断的客服机器人。

这个中台的模式是：先让用户和我们的AI客服聊天，当AI客服无法处理或用户情绪激动时，再将流量导向人工平台。我在这边主要负责了三个围绕优化用户和AI聊天体验的需求。

## 需求一：干预用户的“转人工”请求

![[Pasted image 20251110204418.png]]

这个需求的背景是，有些用户的需求其实AI客服可以解决，但他们出于对AI的不信任，一进来就直接要求转人工，造成了不必要的资源浪费。我们的目标是在尽可能保证用户满意度的情况下，拦截这类请求，引导他们使用AI客服，节省我们人工客服的花费。但同时，对于需求紧急（如转账金额有问题）且情绪激动的用户，我们应该让他直接转人工。

我们的方案是：用户的请求先进来，转发给AI平台进行情绪判断。AI平台会将情绪映射成不同等级，如果是强烈的负面情绪，就直接转人工。如果是普通情绪，我们会进行干预。当轻微的负面情绪达到阈值之后，我们也会主动为其转人工。

具体的实现是：我们接收AI客服平台转发来的六个等级的情绪标识。例如，“疑惑”会被识别为轻微负面情绪，“愤怒”则是强烈负面情绪。我们的工作流接收到情绪后，会结合用户的上下文和本次输入，查询所属的业务领域和场景，然后用RAG（检索增强生成）召回相关的知识，再由AI生成一段安抚性的文本。

这里为了让AI能准确的识别到设置的情绪，我们通过tngd提供的测试集，以及自己补充的马来语，粤语等小语种的语言特征集合构建了一个评测集，通过对情绪进行描述，并将测试过程中遇到的bad case 作为反面例子加入到提示词中，来调试提示词直到模型可以通过测试集。

这个情绪等级和安抚文本会一起返回给我们的后端中台。我们在会话（Conversation）维度维护了一个情绪计数器来统计该用户在对话中的情绪积累情况，当用户本次会话中的负面情绪累积达到设定阈值后，会为他弹出一个转人工卡片，并将计数器全部归零。

这里主要面临了几个问题。首先是并发安全，因为计数器是动态存储在一个扩展字段（externalInfo）里的。但由于我们和前端使用WebSocket连接，并通过一个ConcurrentHashMap以用户ID为Key来维护连接，确保了同一用户同一时间只有一个链接，间接保证了线程安全。

其次，为了避免用户看到多张可点击的转人工卡片，我们利用蚂蚁的缓存（zCache，其实是Redis的一个变体）来存储已发送的卡片标识，并设置一小时的过期时间。但这里有一个性能和数据一致性的问题：如果用户聊了超过一小时，缓存过期了，此时他断开连接再重连，我们会从数据库恢复他的历史会话。如果这时他再次触发了转人工的阈值，就可能出现两张卡片。为了解决这个问题，我们在发送新卡片前，会先去数据库里检查是否存在未被点击的、有效的旧卡片，通过这种方式确保了需求的实现。

## 需求二：相似意图识别

这个场景是，用户在聊天时，可能之前有未处理完的类似工单。如果我们在聊天中识别到他的问题和历史问题相似，就会主动弹出那个未关闭的历史工单。

这里的识别工作也是在工作流中完成的。Lazada那边会给我们提供三层分类的意图。我当时也参与了意图识别模型的评测工作。我们利用他们提供的真实数据集，通过提示词工程（Prompt Engineering）进行优化。首先在提示词里规定好每个意图的定义、场景和案例，并用 few-shot 的方式提供正向例子。然后，我们会自动化地跑测试集，把识别不准的 bad case 拿出来分析。因为我们要求模型输出思维链（Chain-of-Thought, CoT），所以可以根据它的思考过程定位误判的原因，然后相应地调整提示词，并将这个 bad case 也加入到提示词中，通过这种迭代来逐步提高准确率。

当识别到相似工单后，后端会进行推送。这里有一个体验上的需求：如果我们只识别出了最宽泛的第一层意图并进行了推送，而用户没有点击，那么在下一次对话中，如果依然只能识别出第一层意D图，我们就不应再次推送，避免打扰用户。直到我们能识别出更精准的第二层意图，并且匹配到相似工单后，才会再次推送。这个分阶段推送的逻辑，我们也是通过在会话的扩展字段中加入状态标识符来实现的。

关于这个功能，我还有一个后续的想法：目前我们只能推送用户自己的历史工单，但其实很多人的问题是相似的。未来可以考虑在脱敏后，从整个数据库中搜索其他用户遇到类似问题并已解决的工单，把解决方案分享出来，这样可以进一步减少转人工的请求。

需求三：定时任务与会话自动关闭

我们有一个需求是，如果一个会话超过15分钟没有新消息，就需要自动结束它。我们的服务是多机部署的，WebSocket链接维护在每台服务器的内存里。

我们的方案是这样的：

任务发现（单机定时任务）： 每台机器用Spring Task定时扫描本机内存中维护的WebSocket链接，找出超时的连接，并将这些连接信息插入到统一的任务数据库表中。
任务执行（分布式定时任务）： 通过分布式定时任务（如XXL-JOB）选举一台机器，从任务表中拉取所有待关闭的会话，批量提交给人工平台进行关闭同步。
结果校验（分布式定时任务）： 一段时间后，再由一个定时任务去轮询人工平台，查询处理结果。对于处理失败的任务，我们会将其状态改回初始状态，以便在下一轮重试。
为了提升性能，我们做了两点优化。首先，我们的数据库是分库分表（10库100表）的，所以在执行任务时，我们会利用线程池，将任务拆分成100个分片并行处理，一个线程处理一个库中的10张表。其次，为了加快从任务表中查询待处理任务的速度，我们对任务状态（status）和消息ID（messageId）创建了联合索引。因为状态只有几种（如INIT, COMPLETE, FAILED），通过这个索引可以快速定位到所有处于INIT状态的任务，并且利用了覆盖索引，避免了回表查询，大大加快了扫描速度。

其他AI Agent工作

除了客服中台，我还搭建了一个新人入职引导的Agent工作流。新人入职后，可以通过这个Agent查询入职流程中遇到的任何问题。它的核心是一个RAG流程：改写用户问题 -> 快速问答库召回 -> 如果未命中，则进行向量数据库（语雀）召回 -> 将召回的知识填充到提示词中 -> 由大模型生成答案。

这里遇到的一个主要挑战是知识库里存在很多历史遗留的超长文档，一次全文召回很容易撑爆模型的上下文窗口。我们最后的解决方案是手动对这些超长文档进行分析和结构化拆解，将一个大文档拆分成多个逻辑独立的短文档，并添加特定的Tag来优化向量匹配。为了尽可能利用上下文空间，我们还写了一个Java脚本，用一个与模型匹配的Tokenizer来计算召回文档的Token数量，然后按相关度从高到低动态填充，直到塞满上下文为止。

另外，我们还在搭建一个能自动生成单元测试的Agent。这个Agent运用了ReAct的思想，它能调用代码仓库的API等工具，通过“思考-行动-观察”的循环，不断验证代码依赖、分析调用链，来生成覆盖场景更全面的测试用例，并最终自动生成接口文档，归档到语雀。为了保证其可靠性，我们在提示词中设计了SOP（标准作业程序），要求它在每次调用工具后都进行自我检查，从而降低产生幻觉的风险。