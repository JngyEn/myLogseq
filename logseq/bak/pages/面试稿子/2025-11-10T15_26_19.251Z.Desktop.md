
## 自我介绍

面试官你好，我来自厦门大学马来西亚分校，本科专业是计算机科学与技术。我主要的经历有两段，一段是在蚂蚁集团的后端开发实习，另一段是在学校和一个团队搭建了一个校园论坛App，目前有3000多的日活。我先从蚂蚁的实习经历开始讲吧。

我在蚂蚁的实习主要做两部分工作。第一部分就是您刚才提到的，最近比较火的AI Agent和工作流的搭建。另一部分是我们做了一个客服中台，对接东南亚最大的国际电商Lazada。我们作为客服中台，对接了他们原有的人工客服平台，并用我们自研的工作流替换了他们原本基于规则判断的客服机器人。

这个中台的模式是：先让用户和我们的AI客服聊天，当AI客服无法处理或用户情绪激动时，再将流量导向人工平台。我在这边主要负责了三个围绕优化用户和AI聊天体验的需求。

面试官您好，我毕业于厦门大学马来西亚分校计算机科学与技术专业。
我的主要经历有两段，一段是在蚂蚁集团的后端开发实习，另一段是参与开发一个综合校园社媒App。在蚂蚁集团的实习期间，我主要负责了两部分工作。第一部分是参与了新人入职引导AI Agent和工作流的搭建。另一部分是参与对接东南亚最大的电子钱包tngd的客服中台开发。我们作为客服中台，对接了他们原有的人工客服平台，并用我们自研的工作流替换了他们原本基于规则判断的客服机器人。

这个中台的模式是：先让用户和我们的AI客服聊天，当AI客服无法处理或用户情绪激动时，再将流量导向人工平台。我在这边主要负责了三个围绕优化用户和AI聊天体验的需求。

---
两个部分，一部分是构建了用户和客服对话的平台，客服可能是人工客服或者转接给agent客服。另一部分是对接另一个组做的agent。

## 需求一：干预用户的“转人工”请求

![[Pasted image 20251110204418.png]]

这个需求的背景是，有些用户的需求其实AI客服可以解决，但他们出于对AI的不信任，一进来就直接要求转人工，造成了不必要的资源浪费。我们的目标是在尽可能保证用户满意度的情况下，拦截这类请求，引导他们使用AI客服，节省我们人工客服的花费。但同时，对于需求紧急（如转账金额有问题）且情绪激动的用户，我们应该让他直接转人工。

我们的方案是：用户的请求先进来，转发给AI平台进行情绪判断。AI平台会将情绪映射成不同等级，如果是强烈的负面情绪，就直接转人工。如果是普通情绪，我们会进行干预。当轻微的负面情绪达到阈值之后，我们也会主动为其转人工。

具体的实现是：我们接收AI客服平台转发来的六个等级的情绪标识。例如，“疑惑”会被识别为轻微负面情绪，“愤怒”则是强烈负面情绪。我们的工作流接收到情绪后，会结合用户的上下文和本次输入，查询所属的业务领域和场景，然后用RAG（检索增强生成）召回相关的知识，再由AI生成一段安抚性的文本。

这里为了让AI能准确的识别到设置的情绪，我们通过tngd提供的测试集，以及自己补充的马来语，粤语等小语种的语言特征集合构建了一个评测集，通过对情绪进行描述，并将测试过程中遇到的bad case 作为反面例子加入到提示词中，来调试提示词直到模型可以通过测试集。

这个情绪等级和安抚文本会一起返回给我们的后端中台。我们在会话（Conversation）维度维护了一个情绪计数器来统计该用户在对话中的情绪积累情况，当用户本次会话中的负面情绪累积达到设定阈值后，会为他弹出一个转人工卡片，并将计数器全部归零。

这里主要面临了几个问题。

首先是从会话的extInfo中读取数据，修改数据，写回数据非原子操作导致的并发问题，高并发情况下可能会出现多个线程之间数据不可见读取到相同的值，造成数据丢失的情况。通常情况下我们会选择用缓存构造分布式锁，或者数据库层面添加版本号使用乐观锁或者数据库层面加行锁的方式来避免竞争。但是在我们websocket连接前后端发送消息的场景下，利用websocket长链接的天然特性来间接的保证了计数器的线程安全性，达到无锁操作。此外还可以通过消息队列异步处理，但是我们客服场景要求实时性，所以不考虑。


第二个问题是需要保证用户在同一会话生命周期内只能看到一张可用的转人工卡片。我们使用zCache缓存已发送的转人工卡片标识，并设置1小时的过期时间。这样做的优点是缓存的低延迟特性能快速响应用户激动时的转接需求。但是也引入了缓存一致性的问题，当用户会话超过一小时时，缓存会过期；此时如果用户断开连接再重连，我们从数据库恢复其历史会话后，会留存有他未点击的转人工卡片，若他再次触发转人工阈值，系统就可能发送第二张卡片，导致需求不满足。为了解决这个边界问题，我们引入了数据库的二次检查逻辑。在发送新的转人工卡片前检测到缓存中没有卡片，则会先去数据库查询该会话是否存在未被点击的、有效的转人工卡片。保证数据一致性。

其实也是完全依赖数据库检查，不使用缓存，每次都通过DB查询判断是否存在有效卡片。其优点是逻辑更简单，没有一致性漏洞。但缺点是由于卡片的激活状态存储在message表的extInfo字段中，是JSON格式字符串，数据库很难通过SQL直接高效地检索，必须将最近的卡片消息拉到内存解析判断，这会导致转人工场景的响应延迟增加。而转人工往往发生在用户情绪最激动的时刻，高延迟会严重影响体验。

此外这里还有一个考虑是保证用户在聊天的过程中更换设备后，连接到不同的服务器的情况下仍然可以保证信息连续。

也就是我们的踢蹬机制

对于设备切换，我们会用分布式缓存缓存建立连接的用户ID，value为轻量级的设备ID和连接ID，同时在内存中缓存用户的具体websocket Netty ChannelHandlerContext 信息，这个信息是不可序列化的，所以只能放置在内存中。当有新的连接创建请求发送时

## 需求二：相似意图识别

![[Pasted image 20251110222251.png]]

这个场景是，用户在聊天时，可能之前有未处理完的类似工单。如果我们在聊天中识别到他的问题和历史问题相似，就会主动弹出那个未关闭的历史工单。

这里的识别工作也是在工作流中完成的。Lazada那边会给我们提供三层分类的意图。我当时也参与了意图识别模型的评测工作。我们利用他们提供的真实数据集，通过提示词工程（Prompt Engineering）进行优化。首先在提示词里规定好每个意图的定义、场景和案例，并用 few-shot 的方式提供正向例子。然后，我们会自动化地跑测试集，把识别不准的 bad case 拿出来分析。因为我们要求模型输出思维链（Chain-of-Thought, CoT），所以可以根据它的思考过程定位误判的原因，然后相应地调整提示词，并将这个 bad case 也加入到提示词中，通过这种迭代来逐步提高准确率。

当识别到相似工单后，后端会进行推送。这里有一个体验上的需求：如果我们只识别出了最宽泛的第一层意图并进行了推送，而用户没有点击，那么在下一次对话中，如果依然只能识别出第一层意D图，我们就不应再次推送，避免打扰用户。直到我们能识别出更精准的第二层意图，并且匹配到相似工单后，才会再次推送。这个分阶段推送的逻辑，我们也是通过在会话的扩展字段中加入状态标识符来实现的。

关于这个功能，我还有一个后续的想法：目前我们只能推送用户自己的历史工单，但其实很多人的问题是相似的。未来可以考虑在脱敏后，从整个数据库中搜索其他用户遇到类似问题并已解决的工单，把解决方案分享出来，这样可以进一步减少转人工的请求。

## 需求三：定时任务与会话自动关闭

![[Pasted image 20251110222336.png]]

我们有一个需求是，如果一个会话超过15分钟没有新消息，就需要自动结束它。我们的服务是多机部署的，WebSocket链接维护在每台服务器的内存里。

我们的方案是这样的：

任务发现（单机定时任务）： 每台机器用Spring Task定时扫描本机内存中维护的WebSocket链接，找出超时的连接，并将这些连接信息插入到统一的任务数据库表中。
任务执行（分布式定时任务）： 通过分布式定时任务（如XXL-JOB）选举一台机器，从任务表中拉取所有待关闭的会话，批量提交给人工平台进行关闭同步。
结果校验（分布式定时任务）： 一段时间后，再由一个定时任务去轮询人工平台，查询处理结果。对于处理失败的任务，我们会将其状态改回初始状态，以便在下一轮重试。
为了提升性能，我们做了两点优化。首先，我们的数据库是分库分表（10库100表）的，所以在执行任务时，我们会利用线程池，将任务拆分成100个分片并行处理，一个线程处理一个库中的10张表。其次，为了加快从任务表中查询待处理任务的速度，我们对任务状态（status）和消息ID（messageId）创建了联合索引。因为状态只有几种（如INIT, COMPLETE, FAILED），通过这个索引可以快速定位到所有处于INIT状态的任务，并且利用了覆盖索引，避免了回表查询，大大加快了扫描速度。

## 其他AI Agent工作

![[Pasted image 20251110222355.png]]

除了客服中台，我还搭建了一个新人入职引导的Agent工作流。新人入职后，可以通过这个Agent查询入职流程中遇到的任何问题。它的核心是一个RAG流程：改写用户问题 -> 快速问答库召回 -> 如果未命中，则进行向量数据库（语雀）召回 -> 将召回的知识填充到提示词中 -> 由大模型生成答案。

这里遇到的一个主要挑战是知识库里存在很多历史遗留的超长文档，一次全文召回很容易撑爆模型的上下文窗口。我们最后的解决方案是手动对这些超长文档进行分析和结构化拆解，将一个大文档拆分成多个逻辑独立的短文档，并添加特定的Tag来优化向量匹配。为了尽可能利用上下文空间，我们还写了一个Java脚本，用一个与模型匹配的Tokenizer来计算召回文档的Token数量，然后按相关度从高到低动态填充，直到塞满上下文为止。

另外，我们还在搭建一个能自动生成单元测试的Agent。这个Agent运用了ReAct的思想，它能调用代码仓库的API等工具，通过“思考-行动-观察”的循环，不断验证代码依赖、分析调用链，来生成覆盖场景更全面的测试用例，并最终自动生成接口文档，归档到语雀。为了保证其可靠性，我们在提示词中设计了SOP（标准作业程序），要求它在每次调用工具后都进行自我检查，从而降低产生幻觉的风险。